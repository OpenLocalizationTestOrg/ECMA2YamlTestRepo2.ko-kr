### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.SpeechRecognitionEngine
  id: SpeechRecognitionEngine
  children:
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  - System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  - System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  - System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  - System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  - System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  - System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  - System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  - System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  - System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  langs:
  - csharp
  name: SpeechRecognitionEngine
  nameWithType: SpeechRecognitionEngine
  fullName: System.Speech.Recognition.SpeechRecognitionEngine
  type: Class
  summary: "액세스 하 고 처리 중인 음성 인식 엔진 관리 방법을 제공 합니다."
  remarks: "설치 된 음성 인식기에 대 한이 클래스의 인스턴스를 만들 수 있습니다. 인식기가 설치 되어 있는 방법에 대 한 정보를 얻으려면 정적을 사용 하 여 <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       이 클래스 음성 인식 엔진 프로세스 내에서 실행, 되며 음성 인식의 다양 한 측면에 대 한 제어를 다음과 같이 제공:-를 프로세스에서 음성 인식기를 만드는 중 하나를 사용 하 여는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A>생성자.</xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A>      -음성 인식 문법을 사용 하 여 관리할는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A>메서드 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>      -인식기에 대 한 입력을 구성 하려면 다음을 수행 합니다 사용 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>, 또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>      -음성 인식 기능을 수행 하려면 다음을 수행 합니다는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>      -인식 대기 또는 예기치 않은 입력을 처리 하는 방법을 수정 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -인식기에서 반환 하는 대체 항목의 수를 변경 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A> 인식기에서 인식 결과 반환 합니다.는 <xref:System.Speech.Recognition.RecognitionResult>개체입니다.</xref:System.Speech.Recognition.RecognitionResult>      -인식기에 변경 내용을 동기화를 사용 하 여는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> 인식기에서 둘 이상의 스레드를 사용 하 여 작업을 수행할 수 있습니다.      -인식기에 대 한 입력을 에뮬레이트 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>       개체를 인스턴스화할 하는 프로세스의 사용 하기 위한 SpeechRecognitionEngine 개체가입니다. 반대로, <xref:System.Speech.Recognition.SpeechRecognizer>합니다. 하고자 하는 응용 프로그램과 함께 단일 인식기를 공유 합니다.</xref:System.Speech.Recognition.SpeechRecognizer>      > [!NOTE] > 항상 호출 <xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A>음성 인식기에 대 한 마지막 참조를 해제 하기 전에.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A> 가비지 수집기 인식기 개체를 호출할 때까지 사용 중인 리소스를 해제 되지 것입니다 그렇지 않으면 `Finalize` 메서드."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. Because this example uses the `Multiple` mode of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> method, it performs recognition until you close the console window or stop debugging.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: 'public class SpeechRecognitionEngine : IDisposable'
  inheritance:
  - System.Object
  implements:
  - System.IDisposable
  inheritedMembers: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  id: '#ctor'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine()
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine()
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "새 인스턴스를 초기화는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 클래스는 시스템에 대 한 기본 음성 인식기를 사용 합니다."
  remarks: "음성 인식기에서 음성 인식 기능을 시작 하려면 먼저 하나 이상의 인식 문법을 로드할 하 고 인식기에 대 한 입력을 구성 해야 합니다.       문법에 로드 하려면 호출 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       오디오 입력을 구성 하려면 다음 방법 중 하나를 사용:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  syntax:
    content: public SpeechRecognitionEngine ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  id: '#ctor(System.Globalization.CultureInfo)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(CultureInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "새 인스턴스를 초기화는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 클래스는 지정 된 로캘에 대 한 기본 음성 인식기를 사용 합니다."
  remarks: "Microsoft Windows와 System.Speech API는 모든 유효한 언어 국가 코드를 받습니다. 에 지정 된 언어를 사용 하 여 음성 인식을 수행 하는 `CultureInfo` 인수를 지 원하는 언어 국가 코드를 설치 해야 하는 음성 인식 엔진입니다. Microsoft Windows 7과 함께 제공 된 음성 인식 엔진 다음 언어 국가 코드를 사용 합니다.      -EN-GB 합니다. 영어 (영국)-EN-US입니다. 영어 (미국)-d e d E. 독일어 (독일)-ES-ES 합니다. 스페인어 (스페인)-fr fr. 프랑스어 (프랑스)-JA-JP 합니다. 일본어 (일본)-ZH-CN 합니다. 중국어 (중국)-zh-tw로 제공 합니다. 중국어 (대만) 두 문자 언어 코드 &quot;en&quot;, &quot;fr&quot; 또는 &quot;es&quot; 등도 허용 됩니다.       음성 인식기에서 인식을 시작 하려면 먼저 하나 이상의 음성 인식 문법을 로드할 하 고 인식기에 대 한 입력을 구성 해야 합니다.       문법에 로드 하려면 호출 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       오디오 입력을 구성 하려면 다음 방법 중 하나를 사용:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer for the en-US locale.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public SpeechRecognitionEngine (System.Globalization.CultureInfo culture);
    parameters:
    - id: culture
      type: System.Globalization.CultureInfo
      description: "음성 인식기에서 지원 해야 하는 로캘."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions:
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "지정 된 로캘을 지 원하는 없는 설치 된 음성 인식기 또는 <code> culture </code> 고정 문화권입니다."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Culture</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  id: '#ctor(System.Speech.Recognition.RecognizerInfo)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(RecognizerInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "새 인스턴스를 초기화는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 정보를 사용 하는 <xref href=&quot;System.Speech.Recognition.RecognizerInfo&quot;> </xref> 인식기에서 사용 하도록 지정 하는 개체입니다."
  remarks: "설치 된 음성 인식기에 대 한이 클래스의 인스턴스를 만들 수 있습니다. 인식기가 설치 되어 있는 방법에 대 한 정보를 가져오려면는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       음성 인식기에서 인식을 시작 하려면 먼저 하나 이상의 음성 인식 문법을 로드할 하 고 인식기에 대 한 입력을 구성 해야 합니다.       문법에 로드 하려면 호출 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       오디오 입력을 구성 하려면 다음 방법 중 하나를 사용:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer that supports the English language.  \n  \n```c#  \n using System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Select a speech recognizer that supports English.  \n      RecognizerInfo info = null;  \n      foreach (RecognizerInfo ri in SpeechRecognitionEngine.InstalledRecognizers())  \n      {  \n        if (ri.Culture.TwoLetterISOLanguageName.Equals(\"en\"))  \n        {  \n          info = ri;  \n          break;  \n        }  \n      }  \n      if (info == null) return;  \n  \n      // Create the selected recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(info))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public SpeechRecognitionEngine (System.Speech.Recognition.RecognizerInfo recognizerInfo);
    parameters:
    - id: recognizerInfo
      type: System.Speech.Recognition.RecognizerInfo
      description: "특정 음성 인식기에 대 한 정보입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  id: '#ctor(System.String)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(String)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "새 인스턴스를 초기화는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 사용할 인식기의 이름을 지정 하는 문자열 매개 변수를 사용 하 여 클래스입니다."
  remarks: "토큰 이름 인식기의 값인는 <xref:System.Speech.Recognition.RecognizerInfo.Id%2A>속성의는 <xref:System.Speech.Recognition.RecognizerInfo>에서 반환 된 개체는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>인식기 속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A> </xref:System.Speech.Recognition.RecognizerInfo> </xref:System.Speech.Recognition.RecognizerInfo.Id%2A> 설치 된 모든 인식기의 컬렉션을 사용 정적 <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       음성 인식기에서 인식을 시작 하려면 먼저 하나 이상의 음성 인식 문법을 로드할 하 고 인식기에 대 한 입력을 구성 해야 합니다.       문법에 로드 하려면 호출 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       오디오 입력을 구성 하려면 다음 방법 중 하나를 사용:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and creates an instance of the Speech Recognizer 8.0 for Windows (English - US).  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an instance of the Microsoft Speech Recognizer 8.0 for  \n      // Windows (English - US).  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(\"MS-1033-80-DESK\"))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized += new EventHandler(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public SpeechRecognitionEngine (string recognizerId);
    parameters:
    - id: recognizerId
      type: System.String
      description: "사용할 음성 인식기의 토큰 이름입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions:
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "토큰 이름이 없는 음성 인식기가 설치 되어 또는 <code> recognizerId </code> 은 빈 문자열 (&quot;&quot;)."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>recognizerId</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  id: AudioFormat
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "수신 된 오디오의 형식을 가져옵니다는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>합니다."
  remarks: "오디오 입력을 구성 하려면 다음 방법 중 하나를 사용:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The example below uses AudioFormat to obtain and display audio format data.  \n  \n```  \nstatic void DisplayAudioDeviceFormat(Label label, SpeechRecognitionEngine recognitionEngine)   \n{  \n  \n  if (recognitionEngine != null && label != null)   \n  {  \n    label.Text = String.Format(\"Encoding Format:         {0}\\n\" +  \n          \"AverageBytesPerSecond    {1}\\n\" +  \n          \"BitsPerSample            {2}\\n\" +  \n          \"BlockAlign               {3}\\n\" +  \n          \"ChannelCount             {4}\\n\" +  \n          \"SamplesPerSecond         {5}\",  \n          recognitionEngine.AudioFormat.EncodingFormat.ToString(),  \n          recognitionEngine.AudioFormat.AverageBytesPerSecond,  \n          recognitionEngine.AudioFormat.BitsPerSample,  \n          recognitionEngine.AudioFormat.BlockAlign,  \n          recognitionEngine.AudioFormat.ChannelCount,  \n          recognitionEngine.AudioFormat.SamplesPerSecond);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }
    return:
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "에 대 한 입력에 오디오 형식의 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 인스턴스, 또는 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> 입력 구성 하지 않거나 null 입력으로 설정 하는 경우."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  id: AudioLevel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "수신 된 오디오의 수준을 가져옵니다는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>합니다."
  remarks: "값 0 대기를 나타내고 100 최대 입력된 부피를 나타냅니다."
  syntax:
    content: public int AudioLevel { get; }
    return:
      type: System.Int32
      description: "0에서 100 사이의 음성 인식기에서 입력의 오디오 수준입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  id: AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioLevelUpdated
  nameWithType: SpeechRecognitionEngine.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "발생 시기는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 오디오 입력 값의 수준을 보고 합니다."
  remarks: "<xref:System.Speech.Recognition.SpeechRecognitionEngine>1 초에 여러 번이이 이벤트를 발생 시킵니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine> 응용 프로그램이 실행 중인 컴퓨터에는 이벤트가 발생 하는 빈도 따라 다릅니다.       오디오 수준에서 이벤트의 시간을 가져오려면 <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>.</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs> 연결된의 속성</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> 을 사용 하 여 오디오 현재 수준의 인식기에 대 한 입력을 사용 하면 인식기 <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A>       AudioLevelUpdated 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example adds a handler for the AudioLevelUpdated event to a <xref:System.Speech.Recognition.SpeechRecognitionEngine> object. The handler outputs the new audio level to the console.  \n  \n```  \nprivate SpeechRecognitionEngine recognizer;  \n  \n// Initialize the SpeechRecognitionEngine object.   \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognitionEngine();  \n  \n  // Add an event handler for the AudioLevelUpdated event.  \n  recognizer.AudioLevelUpdated +=   \n   new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  \n  \n  // Add other initialization code here.  \n  \n}  \n  \n// Write the audio level to the console when the AudioLevelUpdated event is raised.  \nvoid recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  \n{  \n  Console.WriteLine(\"The audio level is now: {0}.\", e.AudioLevel);  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs> AudioLevelUpdated;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  id: AudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "에 대 한 입력을 제공 하는 장치에 의해 생성 되 고 오디오 스트림의 현재 위치를 가져옵니다는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>합니다."
  remarks: "AudioPosition 속성에는 입력된 장치 위치에 생성 된 오디오 스트림 참조합니다. 반면,는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>속성 오디오 입력 내의 인식기에서 위치를 참조 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> 이 위치는 다를 수 있습니다. 인식기에서 받는 경우 하지는 자신이 입력 하 아직 인식 결과 다음 값을 생성 합니다. 예를 들어는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>AudioPosition 속성의 값 보다 작아야 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>"
  example:
  - "In the following example, the in-process speech recognizer uses a dictation grammar to match speech input. A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> event writes to the console the AudioPosition, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>, and  <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A> when the speech recognizer detects speech at its input.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine for US English.  \n      using (recognizer = new SpeechRecognitionEngine(  \n        new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create a grammar for finding services in different cities.  \n        Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n        Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n        GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n        findServices.Append(services);  \n        findServices.Append(\"near\");  \n        findServices.Append(cities);  \n  \n        // Create a Grammar object from the GrammarBuilder and load it to the recognizer.  \n        Grammar servicesGrammar = new Grammar(findServices);  \n        recognizer.LoadGrammarAsync(servicesGrammar);  \n  \n        // Add handlers for events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n  \n        // Start asynchronous recognition.  \n        recognizer.RecognizeAsync();  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Gather information about detected speech and write it to the console.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Speech detected:\");  \n      Console.WriteLine(\"  Audio level: \" + recognizer.AudioLevel);  \n      Console.WriteLine(\"  Audio position at the event: \" + e.AudioPosition);  \n      Console.WriteLine(\"  Current audio position: \" + recognizer.AudioPosition);  \n      Console.WriteLine(\"  Current recognizer audio position: \" +   \n        recognizer.RecognizerAudioPosition);  \n    }  \n  \n    // Write the text of the recognition result to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"\\nSpeech recognized: \" + e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan AudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "오디오 입력된 장치에 의해 생성 되 고 스트림의 현재 위치입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  id: AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognitionEngine.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "발생 시기는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 오디오 신호의 문제를 발견 합니다."
  remarks: "어떤 문제가 발생 한을 가져오려면 <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>.</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> 연결된의 속성</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> 을 사용 하 여       AudioSignalProblemOccurred 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example defines an event handler that gathers information about an AudioSignalProblemOccurred event.  \n  \n```  \nprivate SpeechRecognitionEngine recognizer;  \n  \n// Initialize the speech recognition engine.  \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognitionEngine();  \n  \n  // Add a handler for the AudioSignalProblemOccurred event.  \n  recognizer.AudioSignalProblemOccurred +=   \n    new EventHandler<AudioSignalProblemOccurredEventArgs>(  \n      recognizer_AudioSignalProblemOccurred);  \n}  \n  \n// Gather information when the AudioSignalProblemOccurred event is raised.  \nvoid recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  \n{  \n  StringBuilder details = new StringBuilder();  \n  \n  details.AppendLine(\"Audio signal problem information:\");  \n  details.AppendFormat(  \n    \" Audio level:               {0}\" + Environment.NewLine +  \n    \" Audio position:            {1}\" + Environment.NewLine +  \n    \" Audio signal problem:      {2}\" + Environment.NewLine +  \n    \" Recognition engine audio position: {3}\" + Environment.NewLine,  \n    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  \n    e.recoEngineAudioPosition);  \n  \n  // Insert additional event handler code here.  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> AudioSignalProblemOccurred;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  id: AudioState
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "수신 된 오디오의 상태를 가져옵니다는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>합니다."
  remarks: "AudioState 속성의 멤버와 오디오 상태를 나타내는 <xref:System.Speech.Recognition.AudioState>열거형.</xref:System.Speech.Recognition.AudioState>"
  syntax:
    content: public System.Speech.Recognition.AudioState AudioState { get; }
    return:
      type: System.Speech.Recognition.AudioState
      description: "음성 인식기에 오디오 입력의 상태입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioState*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  id: AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioStateChanged
  nameWithType: SpeechRecognitionEngine.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "오디오의 상태 변경을 수신 하는 경우 발생 하는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>합니다."
  remarks: "이벤트의 시간에 오디오 상태를 가져오려면 <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> <xref:System.Speech.Recognition.AudioStateChangedEventArgs>.</xref:System.Speech.Recognition.AudioStateChangedEventArgs> 연결된의 속성</xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> 을 사용 하 여 사용 하 여 인식기에서 인식기에 대 한 입력의 오디오 현재 상태를 가져오려면 <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> 오디오 상태에 대 한 자세한 내용은 참조는 <xref:System.Speech.Recognition.AudioState>열거형.</xref:System.Speech.Recognition.AudioState>       AudioStateChanged 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example uses a handler for the AudioStateChanged event to write the recognizer's new <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> to the console each time it changes, using a member of the <xref:System.Speech.Recognition.AudioState> enumeration.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a grammar.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(\"On this farm he had a\");  \n        farm.Append(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Attach event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine();  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Done.\");  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"The new audio state is: \" + e.AudioState);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs> AudioStateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  id: BabbleTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "시간 간격을 가져오거나는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 인식을 마무리 하기 전에 입력된 포함만 배경 노이즈를 허용 합니다."
  remarks: "음성 인식기 각 대기 및 음성 간을 서로 구별 하는 알고리즘을 있습니다. 인식기에서 인식기의 초기 규칙이 일치 하지 않는 모든 비-대기 입력 배경 노이즈를 로드 하 고 음성 인식 문법을 설정으로 분류 합니다. 임의 시간 제한 간격 내에서 배경 노이즈 및 대기를 수신 하는 인식기를 하는 경우 인식기에서 인식 작업을 완료 합니다.      -인식기 발생 비동기 인식 작업에 대 한는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>이벤트, 여기서는 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName>속성은 `true`, 및 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName>속성은 `null`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>      -인식기 동기 인식 작업 및 에뮬레이션에 대 한 반환 `null`에 유효한 <xref:System.Speech.Recognition.RecognitionResult>.</xref:System.Speech.Recognition.RecognitionResult> 대신       임의 제한 시간을 0으로 설정 하는 경우 인식기에서 임의 시간 제한을 확인을 수행 하지 않습니다. 시간 제한 간격 임의의 음수가 아닌 값일 수 있습니다. 기본값은 0 초입니다."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition that sets the BabbleTimeout and <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> before initiating speech recognition. Handlers for the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> events output event information to the console to demonstrate how the <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> affect recognition operations.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Load a Grammar object.  \n        recognizer.LoadGrammar(CreateServicesGrammar(\"FindServices\"));  \n  \n        // Add event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(  \n            AudioStateChangedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(3);  \n        recognizer.BabbleTimeout = TimeSpan.FromSeconds(2);  \n        recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1);  \n        recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.5);  \n  \n        Console.WriteLine(\"BabbleTimeout: {0}\", recognizer.BabbleTimeout);  \n        Console.WriteLine(\"InitialSilenceTimeout: {0}\", recognizer.InitialSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeout: {0}\", recognizer.EndSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeoutAmbiguous: {0}\", recognizer.EndSilenceTimeoutAmbiguous);  \n        Console.WriteLine();  \n  \n        // Start asynchronous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Single);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Create a grammar and build it into a Grammar object.   \n    static Grammar CreateServicesGrammar(string grammarName)  \n    {  \n  \n      // Create a grammar for finding services in different cities.  \n      Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n      Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n      GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n      findServices.Append(services);  \n      findServices.Append(\"near\");  \n      findServices.Append(cities);  \n  \n      // Create a Grammar object from the GrammarBuilder..  \n      Grammar servicesGrammar = new Grammar(findServices);  \n      servicesGrammar.Name = (\"FindServices\");  \n      return servicesGrammar;  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void AudioStateChangedHandler(  \n      object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"AudioStateChanged ({0}): {1}\",  \n        DateTime.Now.ToString(\"mm:ss.f\"), e.AudioState);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"RecognizeCompleted ({0}):\",  \n        DateTime.Now.ToString(\"mm:ss.f\"));  \n  \n      string resultText;  \n      if (e.Result != null) { resultText = e.Result.Text; }  \n      else { resultText = \"<null>\"; }  \n  \n      Console.WriteLine(  \n        \" BabbleTimeout: {0}; InitialSilenceTimeout: {1}; Result text: {2}\",  \n        e.BabbleTimeout, e.InitialSilenceTimeout, resultText);  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\" Exception message: \", e.Error.Message);  \n      }  \n  \n      // Start the next asynchronous recognition operation.  \n      ((SpeechRecognitionEngine)sender).RecognizeAsync(RecognizeMode.Single);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan BabbleTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "시간 간격의 기간입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "이 속성은 0 초 보다 작게 설정 됩니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  id: Dispose
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Dispose()
  nameWithType: SpeechRecognitionEngine.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "삭제는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 개체입니다."
  syntax:
    content: public void Dispose ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  id: Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Dispose(Boolean)
  nameWithType: SpeechRecognitionEngine.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(Boolean)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "삭제는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 세션 중 사용 되는 개체 및 버전 리소스입니다."
  syntax:
    content: protected virtual void Dispose (bool disposing);
    parameters:
    - id: disposing
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>관리 되는 관리 되지 않는 리소스만 해제 하려면 <xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref> 만 관리 되지 않는 리소스를 해제 합니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  id: EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기에서 오디오 대신 텍스트를 사용 하 여 동기 음성 인식에 대 한 입력 구의 에뮬레이션 합니다."
  remarks: "음성 인식기 발생은 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>이벤트 인식 작업 에뮬레이트되지 않은 마치.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       인식기 Vista 및 Windows 7과 함께 제공 되는 대/소문자를 무시 하 고 입력된 구를에 문법 규칙을 적용 하는 경우 너비를 문자. 이 유형의 비교에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형 값과 <xref:System.Globalization.CompareOptions>및 <xref:System.Globalization.CompareOptions>.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다."
  example:
  - "The code example below is part of a console application that demonstrates emulated input, the associated recognition results, and the associated events raised by the speech recognizer. The example generates the following output.  \n  \n```  \nTestRecognize(\"Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = Smith  \n...Recognition result text = Smith  \n  \nTestRecognize(\"Jones\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Jones; Text = Jones  \n...Recognition result text = Jones  \n  \nTestRecognize(\"Mister\")...  \n SpeechDetected event raised.  \n SpeechHypothesized event raised.  \n  Grammar = Smith; Text = mister  \n SpeechRecognitionRejected event raised.  \n  Grammar = <not available>; Text =  \n...No recognition result.  \n  \nTestRecognize(\"Mister Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = mister Smith  \n...Recognition result text = mister Smith  \n  \npress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace Sre_EmulateRecognize  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Load grammars.  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Smith\"));  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Jones\"));  \n  \n        // Disable audio input to the recognizer.  \n        recognizer.SetInputToNull();  \n  \n        // Add handlers for events raised by the EmulateRecognize method.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n  \n        // Start four synchronous emulated recognition operations.  \n        TestRecognize(recognizer, \"Smith\");  \n        TestRecognize(recognizer, \"Jones\");  \n        TestRecognize(recognizer, \"Mister\");  \n        TestRecognize(recognizer, \"Mister Smith\");  \n      }  \n  \n      Console.WriteLine(\"press any key to exit...\");  \n      Console.ReadKey(true);  \n    }  \n  \n    // Create a simple name grammar.  \n    // Set the grammar name to the surname.  \n    private static Grammar CreateNameGrammar(string surname)  \n    {  \n      GrammarBuilder builder = new GrammarBuilder(\"mister\", 0, 1);  \n      builder.Append(surname);  \n  \n      Grammar nameGrammar = new Grammar(builder);  \n      nameGrammar.Name = surname;  \n  \n      return nameGrammar;  \n    }  \n  \n    // Send emulated input to the recognizer for synchronous recognition.  \n    private static void TestRecognize(  \n      SpeechRecognitionEngine recognizer, string input)  \n    {  \n      Console.WriteLine(\"TestRecognize(\\\"{0}\\\")...\", input);  \n      RecognitionResult result =  \n        recognizer.EmulateRecognize(input,CompareOptions.IgnoreCase);  \n      if (result != null)  \n      {  \n        Console.WriteLine(\"...Recognition result text = {0}\",  \n          result.Text ?? \"<null>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"...No recognition result.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  \n    static void SpeechDetectedHandler(  \n      object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechDetected event raised.\");  \n    }  \n  \n    // Handle events.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechHypothesized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognitionRejected event raised.\");  \n      if (e.Result != null)  \n      {  \n        string grammarName;  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name ?? \"<none>\";  \n        }  \n        else  \n        {  \n          grammarName = \"<not available>\";  \n        }  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          grammarName, e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "인식 작업에 대 한 입력입니다."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "인식 작업에 대 한 결과 또는 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> 는 작업은 실패 하거나 인식기를 사용할 수 없습니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "인식기에 로드 된 음성 인식 문법 없습니다."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>가 빈 문자열 (&quot;&quot;)."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기 오디오 대신 텍스트를 사용 하 여 동기 음성 인식에 특정 단어의 입력을 에뮬레이트하고 인식기에서 단어 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다."
  remarks: "음성 인식기 발생은 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>이벤트 인식 작업 에뮬레이트되지 않은 마치.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       인식기에서 사용 하 여 `compareOptions` 때 문법 규칙 입력된 구문에 적용 합니다. 인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 <xref:System.Globalization.CompareOptions>또는 <xref:System.Globalization.CompareOptions>값이 있는.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 인식기에서 항상 문자 너비를 무시 하 고는 일본어가 나 형식을 무시 하지 않습니다. 또한 인식기에서 줄 바꿈은 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "인식 작업에 대 한 입력이 포함 된 배열 단어 단위입니다."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "인식 작업에 대 한 결과 또는 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> 는 작업은 실패 하거나 인식기를 사용할 수 없습니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "인식기에 로드 된 음성 인식 문법 없습니다."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>wordUnits</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>wordUnits</code>하나 이상 포함 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> 요소입니다."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>포함 된 <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, 또는 <xref:System.Globalization.CompareOptions> 플래그입니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기에서 오디오 대신 텍스트를 사용 하 여 동기 음성 인식에 대 한 입력 구의 에뮬레이트하고 인식기는 구를 검색 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다."
  remarks: "음성 인식기 발생은 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>이벤트 인식 작업 에뮬레이트되지 않은 마치.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       인식기에서 사용 하 여 `compareOptions` 때 문법 규칙 입력된 구문에 적용 합니다. 인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 <xref:System.Globalization.CompareOptions>또는 <xref:System.Globalization.CompareOptions>값이 있는.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 인식기에서 항상 문자 너비를 무시 하 고는 일본어가 나 형식을 무시 하지 않습니다. 또한 인식기에서 줄 바꿈은 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "인식 작업에 대 한 입력된 구입니다."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "인식 작업에 대 한 결과 또는 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> 는 작업은 실패 하거나 인식기를 사용할 수 없습니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "인식기에 로드 된 음성 인식 문법 없습니다."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>가 빈 문자열 (&quot;&quot;)."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>포함 된 <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, 또는 <xref:System.Globalization.CompareOptions> 플래그입니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  id: EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기에서 오디오 대신 텍스트를 사용 하 여 비동기 음성 인식에 대 한 입력 구의 에뮬레이션 합니다."
  remarks: "음성 인식기 발생은 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>이벤트 인식 작업 에뮬레이트되지 않은 마치.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> 인식기에서 인식 비동기 작업이 완료 되 면 발생는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>이벤트.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       인식기 Vista 및 Windows 7과 함께 제공 되는 대/소문자를 무시 하 고 입력된 구를에 문법 규칙을 적용 하는 경우 너비를 문자. 이 유형의 비교에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형 값과 <xref:System.Globalization.CompareOptions>및 <xref:System.Globalization.CompareOptions>.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다."
  example:
  - "The code example below is part of a console application that demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. The example generates the following output.  \n  \n```  \n  \nTestRecognizeAsync(\"Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = Smith  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Smith; Text = Smith  \n Done.  \n  \nTestRecognizeAsync(\"Jones\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Jones; Text = Jones  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Jones; Text = Jones  \n Done.  \n  \nTestRecognizeAsync(\"Mister\")...  \n SpeechDetected event raised.  \n SpeechHypothesized event raised.  \n  Grammar = Smith; Text = mister  \n SpeechRecognitionRejected event raised.  \n  Grammar = <not available>; Text =  \n EmulateRecognizeCompleted event raised.  \n  No recognition result available.  \n Done.  \n  \nTestRecognizeAsync(\"Mister Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = mister Smith  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Smith; Text = mister Smith  \n Done.  \n  \npress any key to exit...  \n```  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SreEmulateRecognizeAsync  \n{  \n  class Program  \n  {  \n    // Indicate when an asynchronous operation is finished.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Load grammars.  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Smith\"));  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Jones\"));  \n  \n        // Configure the audio input.  \n        recognizer.SetInputToNull();  \n  \n        // Add event handlers for the events raised by the  \n        // EmulateRecognizeAsync method.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHander);  \n  \n        // Start four asynchronous emulated recognition operations.  \n        TestRecognizeAsync(recognizer, \"Smith\");  \n        TestRecognizeAsync(recognizer, \"Jones\");  \n        TestRecognizeAsync(recognizer, \"Mister\");  \n        TestRecognizeAsync(recognizer, \"Mister Smith\");  \n      }  \n  \n      Console.WriteLine(\"press any key to exit...\");  \n      Console.ReadKey(true);  \n    }  \n  \n    // Create a simple name grammar.  \n    // Set the grammar name to the surname.  \n    private static Grammar CreateNameGrammar(string surname)  \n    {  \n      GrammarBuilder builder = new GrammarBuilder(\"mister\", 0, 1);  \n      builder.Append(surname);  \n  \n      Grammar nameGrammar = new Grammar(builder);  \n      nameGrammar.Name = surname;  \n  \n      return nameGrammar;  \n    }  \n  \n    // Send emulated input to the recognizer for asynchronous  \n    // recognition.  \n    private static void TestRecognizeAsync(  \n      SpeechRecognitionEngine recognizer, string input)  \n    {  \n      completed = false;  \n  \n      Console.WriteLine(\"TestRecognizeAsync(\\\"{0}\\\")...\", input);  \n      recognizer.EmulateRecognizeAsync(input);  \n  \n      // Wait for the operation to complete.  \n      while (!completed)  \n      {  \n        Thread.Sleep(333);  \n      }  \n  \n      Console.WriteLine(\" Done.\");  \n      Console.WriteLine();  \n    }  \n  \n    static void SpeechDetectedHandler(  \n      object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechDetected event raised.\");  \n    }  \n  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechHypothesized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    // Handle events.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognitionRejected event raised.\");  \n      if (e.Result != null)  \n      {  \n        string grammarName;  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name ?? \"<none>\";  \n        }  \n        else  \n        {  \n          grammarName = \"<not available>\";  \n        }  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          grammarName, e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text );  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void EmulateRecognizeCompletedHander(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" EmulateRecognizeCompleted event raised.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  {0} exception encountered: {1}:\",  \n          e.Error.GetType().Name, e.Error.Message);  \n      }  \n      else if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      else if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "인식 작업에 대 한 입력입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "인식기가 로드 되지 음성 인식 문법 또는 인식기에서 아직 완료 되지 않은 비동기 인식 작업이 정의 되어 있습니다."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>가 빈 문자열 (&quot;&quot;)."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기의 배열을 사용 하 여에 특정 단어의 입력을 에뮬레이션 <xref href=&quot;System.Speech.Recognition.RecognizedWordUnit&quot;> </xref> 비동기 음성 인식 기능에 대 한 오디오 대신 개체를 인식기에서 단어 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다."
  remarks: "음성 인식기 발생은 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>이벤트 인식 작업 에뮬레이트되지 않은 마치.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> 인식기에서 인식 비동기 작업이 완료 되 면 발생는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>이벤트.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       인식기에서 사용 하 여 `compareOptions` 때 문법 규칙 입력된 구문에 적용 합니다. 인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 <xref:System.Globalization.CompareOptions>또는 <xref:System.Globalization.CompareOptions>값이 있는.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 인식기에서 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다. 또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "인식 작업에 대 한 입력이 포함 된 배열 단어 단위입니다."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "인식기가 로드 되지 음성 인식 문법 또는 인식기에서 아직 완료 되지 않은 비동기 인식 작업이 정의 되어 있습니다."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>wordUnits</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>wordUnits</code>하나 이상 포함 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> 요소입니다."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>포함 된 <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, 또는 <xref:System.Globalization.CompareOptions> 플래그입니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기에서 오디오 대신 텍스트를 사용 하 여 비동기 음성 인식에 대 한 입력 구의 에뮬레이트하고 인식기는 구를 검색 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다."
  remarks: "음성 인식기 발생은 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>이벤트 인식 작업 에뮬레이트되지 않은 마치.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> 인식기에서 인식 비동기 작업이 완료 되 면 발생는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>이벤트.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       인식기에서 사용 하 여 `compareOptions` 때 문법 규칙 입력된 구문에 적용 합니다. 인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 <xref:System.Globalization.CompareOptions>또는 <xref:System.Globalization.CompareOptions>값이 있는.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 인식기에서 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다. 또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "인식 작업에 대 한 입력된 구입니다."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "인식기가 로드 되지 음성 인식 문법 또는 인식기에서 아직 완료 되지 않은 비동기 인식 작업이 정의 되어 있습니다."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>가 빈 문자열 (&quot;&quot;)."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>포함 된 <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, 또는 <xref:System.Globalization.CompareOptions> 플래그입니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  id: EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "발생 시기는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 에뮬레이트된 입력의 비동기 인식 작업을 종료 합니다."
  remarks: "각 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>메서드는 비동기 인식 작업을 시작 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine>비동기 작업을 완료 하는 경우 EmulateRecognizeCompleted 이벤트를 발생 시킵니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine>       <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>작업을 발생 시킬 수는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>이벤트.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> EmulateRecognizeCompleted 이벤트는 마지막 이러한 이벤트 인식기에서 지정된 된 작업에 대 한를 발생 시킵니다.       에뮬레이트된 인식에 성공 하면 다음 중 하나를 사용 하 여 인식 결과 액세스할 수 있습니다:- <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>속성에는 <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>EmulateRecognizeCompleted 이벤트의 처리기에는 개체입니다.</xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> </xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>      - <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>속성에는 <xref:System.Speech.Recognition.SpeechRecognizedEventArgs>개체에 대 한 처리기는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>이벤트.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognizedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>       에뮬레이트된 인식 하지 못한 경우, 고 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>이벤트가 발생 하지 않습니다 및 <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>null이 됩니다.</xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>       <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs><xref:System.ComponentModel.AsyncCompletedEventArgs>.</xref:System.ComponentModel.AsyncCompletedEventArgs> 에서 파생</xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>       <xref:System.Speech.Recognition.SpeechRecognizedEventArgs><xref:System.Speech.Recognition.RecognitionEventArgs>.</xref:System.Speech.Recognition.RecognitionEventArgs> 에서 파생</xref:System.Speech.Recognition.SpeechRecognizedEventArgs>       EmulateRecognizeCompleted 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace InProcessRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of an in-process recognizer.  \n      using (SpeechRecognitionEngine recognizer =   \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call mathches the grammar  \n        // and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar  \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Result of 1st call to EmulateRecognizeAsync = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"Result of 2nd call to EmulateRecognizeAsync = No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> EmulateRecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  id: EndSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "대기 간격을 가져오거나는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 인식 작업을 마무리 하기 전에 모호 하지 않은 입력의 끝에서 허용 됩니다."
  remarks: "음성 인식기에서 인식 입력 모호 하지 않은 경우이 시간 제한 간격을 사용 합니다. 지 원하는 인식의 음성 인식 문법에 대 한 예를 들어 &quot;새 게임을 하십시오&quot; 또는 &quot;새 게임&quot; &quot;새 게임을 하십시오&quot; 한 명확한 입력 하 고 &quot;새 게임&quot;은 모호한 입력 합니다.       이 속성 인식 작업을 마무리 하기 전에 음성 인식 엔진 추가 입력에 대 한 대기 하는 시간을 결정 합니다. 제한 시간 간격은 10 초를 0 초에서 수 있습니다. 기본값은 150 밀리초입니다.       모호한 입력에 대 한 제한 시간 간격을 설정 하려면는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>"
  syntax:
    content: public TimeSpan EndSilenceTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "대기 간격의 기간입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "이 속성은 10 초 보다 큰 값 또는 0 초 보다 작게 설정 됩니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  id: EndSilenceTimeoutAmbiguous
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "대기 간격을 가져오거나는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 인식 작업을 마무리 하기 전에 모호한 입력의 끝에 적용 됩니다."
  remarks: "음성 인식기에서 인식 입력이 모호한 경우이 시간 제한 간격을 사용 합니다. 지 원하는 인식의 음성 인식 문법에 대 한 예를 들어 &quot;새 게임을 하십시오&quot; 또는 &quot;새 게임&quot; &quot;새 게임을 하십시오&quot; 한 명확한 입력 하 고 &quot;새 게임&quot;은 모호한 입력 합니다.       이 속성 인식 작업을 마무리 하기 전에 음성 인식 엔진 추가 입력에 대 한 대기 하는 시간을 결정 합니다. 제한 시간 간격은 10 초를 0 초에서 수 있습니다. 기본값은 500 밀리초입니다.       명확한 입력에 대 한 제한 시간 간격을 설정 하려면는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>"
  syntax:
    content: public TimeSpan EndSilenceTimeoutAmbiguous { get; set; }
    return:
      type: System.TimeSpan
      description: "대기 간격의 기간입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "이 속성은 10 초 보다 큰 값 또는 0 초 보다 작게 설정 됩니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  id: Grammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "컬렉션을 가져옵니다는 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> 이 로드 되는 개체 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 인스턴스."
  remarks: ''
  example:
  - "The following example outputs information to the console for each speech recognition grammar that is currently loaded by a speech recognizer.  \n  \n> [!IMPORTANT]\n>  Copy the grammar collection to avoid errors if the collection is modified while this method enumerates the elements of the collection.  \n  \n```c#  \n  \nprivate static void ListGrammars(SpeechRecognitionEngine recognizer)  \n{  \n  string qualifier;  \n  List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n  foreach (Grammar g in grammars)  \n  {  \n    qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n  \n    Console.WriteLine(\"Grammar {0} is loaded and is {1}.\",  \n      g.Name, qualifier);  \n  }  \n}  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar> Grammars { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
      description: "컬렉션 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> 개체입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Grammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  id: InitialSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "시간 간격을 가져오거나는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 인식을 마무리 하기 전에 포함만 대기 입력된을 허용 합니다."
  remarks: "음성 인식기 각 대기 및 음성 간을 서로 구별 하는 알고리즘을 있습니다. 인식기 입력 초기 대기 제한 시간 동안 대기 이면 인식기에서 인식 작업을 완료 합니다.      -인식기 발생 비동기 인식 작업 및 에뮬레이션에 대 한는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>이벤트, 여기서는 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName>속성은 `true`, 및 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName>속성은 `null`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>      -인식기 동기 인식 작업 및 에뮬레이션에 대 한 반환 `null`에 유효한 <xref:System.Speech.Recognition.RecognitionResult>.</xref:System.Speech.Recognition.RecognitionResult> 대신       초기 대기 제한 시간 간격을 0으로 설정 하는 경우 인식기에서 초기 대기 제한 시간 확인 작업을 수행 하지 않습니다. 시간 제한 간격 임의의 음수가 아닌 값일 수 있습니다. 기본값은 0 초입니다."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example sets the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> and InitialSilenceTimeout properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> before initiating speech recognition. Handlers for the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> events output event information to the console to demonstrate how the InitialSilenceTimeout properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> properties affect recognition operations.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Load a Grammar object.  \n        recognizer.LoadGrammar(CreateServicesGrammar(\"FindServices\"));  \n  \n        // Add event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(  \n            AudioStateChangedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(3);  \n        recognizer.BabbleTimeout = TimeSpan.FromSeconds(2);  \n        recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1);  \n        recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.5);  \n  \n        Console.WriteLine(\"BabbleTimeout: {0}\", recognizer.BabbleTimeout);  \n        Console.WriteLine(\"InitialSilenceTimeout: {0}\", recognizer.InitialSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeout: {0}\", recognizer.EndSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeoutAmbiguous: {0}\", recognizer.EndSilenceTimeoutAmbiguous);  \n        Console.WriteLine();  \n  \n        // Start asynchronous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Single);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Create a grammar and build it into a Grammar object.   \n    static Grammar CreateServicesGrammar(string grammarName)  \n    {  \n  \n      // Create a grammar for finding services in different cities.  \n      Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n      Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n      GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n      findServices.Append(services);  \n      findServices.Append(\"near\");  \n      findServices.Append(cities);  \n  \n      // Create a Grammar object from the GrammarBuilder..  \n      Grammar servicesGrammar = new Grammar(findServices);  \n      servicesGrammar.Name = (\"FindServices\");  \n      return servicesGrammar;  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void AudioStateChangedHandler(  \n      object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"AudioStateChanged ({0}): {1}\",  \n        DateTime.Now.ToString(\"mm:ss.f\"), e.AudioState);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"RecognizeCompleted ({0}):\",  \n        DateTime.Now.ToString(\"mm:ss.f\"));  \n  \n      string resultText;  \n      if (e.Result != null) { resultText = e.Result.Text; }  \n      else { resultText = \"<null>\"; }  \n  \n      Console.WriteLine(  \n        \" BabbleTimeout: {0}; InitialSilenceTimeout: {1}; Result text: {2}\",  \n        e.BabbleTimeout, e.InitialSilenceTimeout, resultText);  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\" Exception message: \", e.Error.Message);  \n      }  \n  \n      // Start the next asynchronous recognition operation.  \n      ((SpeechRecognitionEngine)sender).RecognizeAsync(RecognizeMode.Single);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan InitialSilenceTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "대기 간격의 기간입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "이 속성은 0 초 보다 작게 설정 됩니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  id: InstalledRecognizers
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: InstalledRecognizers()
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "현재 시스템에 설치 된 음성 인식기의 모든 정보를 반환합니다."
  remarks: "현재 인식기에 대 한 정보를 가져오려면는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses the collection returned by the InstalledRecognizers method to find a speech recognizer that supports the English language.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Select a speech recognizer that supports English.  \n      RecognizerInfo info = null;  \n      foreach (RecognizerInfo ri in SpeechRecognitionEngine.InstalledRecognizers())  \n      {  \n        if (ri.Culture.TwoLetterISOLanguageName.Equals(\"en\"))  \n        {  \n          info = ri;  \n          break;  \n        }  \n      }  \n      if (info == null) return;  \n  \n      // Create the selected recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(info))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public static System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo> InstalledRecognizers ();
    parameters: []
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizerInfo}
      description: "읽기 전용 컬렉션은 <xref href=&quot;System.Speech.Recognition.RecognizerInfo&quot;> </xref> 설치 인식기를 설명 하는 개체입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  id: LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "동기식으로 로드 한 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> 개체입니다."
  remarks: "인식기에서 예외를 throw 하는 경우는 <xref:System.Speech.Recognition.Grammar>개체는 이미 로드 되어, 비동기적으로 로드 되 고, 또는 모든 인식기로 로드 하지 못했습니다.</xref:System.Speech.Recognition.Grammar> 동일한 <xref:System.Speech.Recognition.Grammar>개체 <xref:System.Speech.Recognition.SpeechRecognitionEngine>.</xref:System.Speech.Recognition.SpeechRecognitionEngine> 의 여러 인스턴스를</xref:System.Speech.Recognition.Grammar> 로드할 수 없습니다. 대신 새를 만들 <xref:System.Speech.Recognition.Grammar>각각에 대 한 개체 <xref:System.Speech.Recognition.SpeechRecognitionEngine>인스턴스.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar>       응용 프로그램을 사용 해야 인식기에서 실행 중인 경우 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>를 로드, 언로드, 또는 사용 안 함 문법 하기 전에 음성 인식 엔진을 일시 중지 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       문법적으로 로드 하는 경우 기본적으로 사용 됩니다. 로드 된 문법을 사용는 <xref:System.Speech.Recognition.Grammar.Enabled%2A>속성.</xref:System.Speech.Recognition.Grammar.Enabled%2A>       로드 하는 <xref:System.Speech.Recognition.Grammar>비동기적으로 개체를 가져오려면는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.Grammar>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar> and loads it into a speech recognizer.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void LoadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "로드할 문법 개체입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "<code>Grammar</code>상태가 올바르지 않습니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  id: LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식 문법을 비동기적으로 로드 합니다."
  remarks: "인식기에서 로드를 완료 하는 경우는 <xref:System.Speech.Recognition.Grammar>개체를 발생 한 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted>이벤트.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted> </xref:System.Speech.Recognition.Grammar> 인식기에서 예외를 throw 하는 경우는 <xref:System.Speech.Recognition.Grammar>개체는 이미 로드 되어, 비동기적으로 로드 되 고, 또는 모든 인식기로 로드 하지 못했습니다.</xref:System.Speech.Recognition.Grammar> 동일한 <xref:System.Speech.Recognition.Grammar>개체 <xref:System.Speech.Recognition.SpeechRecognitionEngine>.</xref:System.Speech.Recognition.SpeechRecognitionEngine> 의 여러 인스턴스를</xref:System.Speech.Recognition.Grammar> 로드할 수 없습니다. 대신 새를 만들 <xref:System.Speech.Recognition.Grammar>각각에 대 한 개체 <xref:System.Speech.Recognition.SpeechRecognitionEngine>인스턴스.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar>       응용 프로그램을 사용 해야 인식기에서 실행 중인 경우 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>를 로드, 언로드, 또는 사용 안 함 문법 하기 전에 음성 인식 엔진을 일시 중지 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       문법적으로 로드 하는 경우 기본적으로 사용 됩니다. 로드 된 문법을 사용는 <xref:System.Speech.Recognition.Grammar.Enabled%2A>속성.</xref:System.Speech.Recognition.Grammar.Enabled%2A>       음성 인식 문법에 동기적으로 로드 하려면 사용 하 여는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>"
  syntax:
    content: public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "음성 인식 문법을 로드 합니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "<code>Grammar</code>상태가 올바르지 않습니다."
  - type: System.OperationCanceledException
    commentId: T:System.OperationCanceledException
    description: "비동기 작업이 취소 되었습니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  id: LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognitionEngine.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "발생 시기는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 의 비동기 로드가 완료 되는 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> 개체입니다."
  remarks: "인식기에서 <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>메서드는 비동기 작업을 시작 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine>는 작업을 완료 하는 경우이 이벤트를 발생 시킵니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine> <xref:System.Speech.Recognition.Grammar>인식기에서 로드 하는 개체 <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>.</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs> 연결된의 속성</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> 을 사용</xref:System.Speech.Recognition.Grammar> 하려면 현재 가져오려는 <xref:System.Speech.Recognition.Grammar>인식기가 로드 하는 개체 인식기에서 사용 하 여 <xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> </xref:System.Speech.Recognition.Grammar>       응용 프로그램을 사용 해야 인식기에서 실행 중인 경우 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>를 로드, 언로드, 또는 사용 안 함 문법 하기 전에 음성 인식 엔진을 일시 중지 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       LoadGrammarCompleted 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example creates an in-process speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example constructs a <xref:System.Speech.Recognition.Grammar> object from each of the completed speech recognition grammars, then asynchronously loads the <xref:System.Speech.Recognition.Grammar> objects to the <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance. Handlers for the recognizer's LoadGrammarCompleted and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events write to the console the name of the <xref:System.Speech.Recognition.Grammar> object that was used to perform the recognition and the text of the recognition result, respectively.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and set its input.  \n      recognizer = new SpeechRecognitionEngine();  \n      recognizer.SetInputToDefaultAudioDevice();  \n  \n      // Add a handler for the LoadGrammarCompleted event.  \n      recognizer.LoadGrammarCompleted +=  \n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n      // Add a handler for the SpeechRecognized event.  \n      recognizer.SpeechRecognized +=  \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n      // Create the \"yesno\" grammar.  \n      Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yeah\" });  \n      SemanticResultValue yesValue =  \n          new SemanticResultValue(yesChoices, (bool)true);  \n      Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"neah\" });  \n      SemanticResultValue noValue =  \n          new SemanticResultValue(noChoices, (bool)false);  \n      SemanticResultKey yesNoKey =  \n          new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n      Grammar yesnoGrammar = new Grammar(yesNoKey);  \n      yesnoGrammar.Name = \"yesNo\";  \n  \n      // Create the \"done\" grammar.  \n      Grammar doneGrammar =  \n        new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n      doneGrammar.Name = \"Done\";  \n  \n      // Create a dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load grammars to the recognizer.  \n      recognizer.LoadGrammarAsync(yesnoGrammar);  \n      recognizer.LoadGrammarAsync(doneGrammar);  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Start asynchronous, continuous recognition.  \n      recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.   \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n  \n        // Add exception handling code here.  \n      }  \n  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs> LoadGrammarCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  id: MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "대체 인식 결과의 최대 수를 가져오거나는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 각 인식 작업을 반환 합니다."
  remarks: "<xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>속성은 <xref:System.Speech.Recognition.RecognitionResult>의 컬렉션을 포함 하는 클래스 <xref:System.Speech.Recognition.RecognizedPhrase>입력의 가능한 해석을 나타내는 개체입니다.</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       MaxAlternates의 기본값은 10입니다."
  syntax:
    content: public int MaxAlternates { get; set; }
    return:
      type: System.Int32
      description: "대체 반환할 결과의 수입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "MaxAlternates 0 보다 작은 값으로 설정 됩니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  id: QueryRecognizerSetting(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: QueryRecognizerSetting(String)
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "인식기에 대 한 설정의 값을 반환합니다."
  remarks: "인식기 설정을 문자열, 64 비트 정수 또는 메모리 주소 데이터를 포함할 수 있습니다. 다음 표에서 Microsoft Speech API (SAPI)에 대해 정의 된 설정을-인식기 규정을 준수 합니다. 다음 설정은 각 인식기 설정을 지원에 대 한 동일한 범위가 있어야 합니다. SAPI 규격 인식기 이러한 설정을 지 원하는 데 필요 하지는 및 기타 설정을 지원할 수 있습니다.      | 이름 | 설명 |   |----------|-----------------|   | `ResourceUsage`| 인식기에서 CPU 소비를 지정합니다. 범위는 0에서 100 까지입니다. 기본값은 50입니다. |   | `ResponseSpeed`| 음성 인식기에서 인식 작업을 완료 하기 전에 대기 모호 하지 않은 입력의 끝에서의 길이 나타냅니다. 범위는 0에서 10, 000 밀리초 (ms) 까지입니다. 이 설정은 인식기에 해당 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>  기본값 = 150ms. |   | `ComplexResponseSpeed`| 음성 인식기에서 인식 작업을 완료 하기 전에 대기 모호한 입력의 끝에 길이 나타냅니다. 범위는 0에서 같고 10, 000ms 까지입니다. 이 설정은 인식기에 해당 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> 기본값은 500 밀리초. |   | `AdaptationOn`| 음향 모델의 적응 ON 인지를 나타냅니다 (값 = `1`) 또는 OFF (값 = `0`). 기본값은 `1` (ON). |   | `PersistedBackgroundAdaptation`| 백그라운드 적용 ON 인지를 나타냅니다 (값 = `1`) 또는 OFF (값 = `0`), 레지스트리에서 설정을 유지 합니다. 기본값은 `1` (ON). |       인식기 설정을 업데이트 하려면 중 사용 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  example:
  - "The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale. The example generates the following output.  \n  \n```  \nSettings for recognizer MS-1033-80-DESK:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 150  \n  ComplexResponseSpeed           = 500  \n  AdaptationOn                   = 1  \n  PersistedBackgroundAdaptation  = 1  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognizerSettings  \n{  \n  class Program  \n  {  \n    static readonly string[] settings = new string[] {  \n      \"ResourceUsage\",  \n      \"ResponseSpeed\",  \n      \"ComplexResponseSpeed\",  \n      \"AdaptationOn\",  \n      \"PersistedBackgroundAdaptation\"  \n    };  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Settings for recognizer {0}:\",  \n          recognizer.RecognizerInfo.Name);  \n        Console.WriteLine();  \n  \n        foreach (string setting in settings)  \n        {  \n          try  \n          {  \n            object value = recognizer.QueryRecognizerSetting(setting);  \n            Console.WriteLine(\"  {0,-30} = {1}\", setting, value);  \n          }  \n          catch  \n          {  \n            Console.WriteLine(\"  {0,-30} is not supported by this recognizer.\",  \n              setting);  \n          }  \n        }  \n      }  \n      Console.WriteLine();  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public object QueryRecognizerSetting (string settingName);
    parameters:
    - id: settingName
      type: System.String
      description: "반환할 설정의 이름입니다."
    return:
      type: System.Object
      description: "설정의 값입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>가 빈 문자열 (&quot;&quot;)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "해당 이름의 인식기 설정을 않아도 됩니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  id: Recognize
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Recognize()
  nameWithType: SpeechRecognitionEngine.Recognize()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "동기 음성 인식 작업을 수행합니다."
  remarks: "이 메서드는 단일 인식 작업을 수행합니다. 인식기에서의 로드 하 고 사용할 음성 인식 문법에 대해이 작업을 수행합니다.       인식기에서이 메서드를 호출 하는 동안 다음과 같은 이벤트를 발생 수:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  인식기에서 음성으로 식별할 수 있는 입력을 감지할 때 발생 합니다.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  입력 현재 문법 중 하 나와 일치 상태가 모호를 만들 때 발생 합니다.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> 인식기에서 인식 작업을 종료 하는 경우 발생 합니다.       인식기에서 발생 하지 않습니다는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>이 메서드를 사용 하는 경우에 이벤트입니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>       인식 메서드 반환는 <xref:System.Speech.Recognition.RecognitionResult>개체 또는 `null` 는 작업은 실패 하는 경우.</xref:System.Speech.Recognition.RecognitionResult>       동기 인식 작업은 다음과 같은 이유로 실패할 수 있습니다.-에 대 한 시간 제한 간격이 만료 되기 전에 음성 인식 되지 않습니다는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -인식 엔진 음성 검색 했지만 로드 및 사용에 일치 하는 항목을 찾은 <xref:System.Speech.Recognition.Grammar>개체입니다.</xref:System.Speech.Recognition.Grammar>       비동기 인식 기능을 수행 하려면 중 하나를 사용는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one recognition operation.  \n  \n```  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SynchronousRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Modify the initial silence time-out value.  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5);  \n  \n        // Start synchronous speech recognition.  \n        RecognitionResult result = recognizer.Recognize();  \n  \n        if (result != null)  \n        {  \n          Console.WriteLine(\"Recognized text = {0}\", result.Text);  \n        }  \n        else  \n        {  \n          Console.WriteLine(\"No recognition result available.\");  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to continue...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult Recognize ();
    parameters: []
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "입력에 대 한 인식 결과 또는 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> 는 작업은 실패 하거나 인식기를 사용할 수 없습니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  id: Recognize(System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Recognize(TimeSpan)
  nameWithType: SpeechRecognitionEngine.Recognize(TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "지정 된 초기 대기 제한 시간으로 동기 음성 인식 작업을 수행합니다."
  remarks: "음성 인식 엔진 감지 하 여 지정 된 시간 간격 내에서 음성 `initialSilenceTimeout` 인수를 인식 단일 인식 작업을 수행 하 고 다음 종료 합니다.  `initialSilenceTimeout` 매개 변수 대체 인식기 <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>       인식기에서이 메서드를 호출 하는 동안 다음과 같은 이벤트를 발생 수:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  인식기에서 음성으로 식별할 수 있는 입력을 감지할 때 발생 합니다.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  입력 현재 문법 중 하 나와 일치 상태가 모호를 만들 때 발생 합니다.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> 인식기에서 인식 작업을 종료 하는 경우 발생 합니다.       인식기에서 발생 하지 않습니다는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>이 메서드를 사용 하는 경우에 이벤트입니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>       <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize>메서드가 반환 되는 <xref:System.Speech.Recognition.RecognitionResult>개체 또는 `null` 는 작업은 실패 하는 경우.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize>       동기 인식 작업은 다음과 같은 이유로 실패할 수 있습니다:-에 대 한 시간 제한 간격이 만료 되기 전에 음성 인식 되지 않습니다는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>또는 `initialSilenceTimeout` 매개 변수.</xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -인식 엔진 음성 검색 했지만 로드 및 사용에 일치 하는 항목을 찾은 <xref:System.Speech.Recognition.Grammar>개체입니다.</xref:System.Speech.Recognition.Grammar>       비동기 인식 기능을 수행 하려면 중 하나를 사용는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one recognition operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SynchronousRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start synchronous speech recognition.  \n        RecognitionResult result = recognizer.Recognize(TimeSpan.FromSeconds(5));  \n  \n        if (result != null)  \n        {  \n          Console.WriteLine(\"Recognized text = {0}\", result.Text);  \n        }  \n        else  \n        {  \n          Console.WriteLine(\"No recognition result available.\");  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to continue...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult Recognize (TimeSpan initialSilenceTimeout);
    parameters:
    - id: initialSilenceTimeout
      type: System.TimeSpan
      description: "음성 인식기에서 허용 하는 시간 간격을만 대기 인식을 마무리 하기 전에 포함 된 입력입니다."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "입력에 대 한 인식 결과 또는 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> 는 작업은 실패 하거나 인식기를 사용할 수 없습니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  id: RecognizeAsync
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsync()
  nameWithType: SpeechRecognitionEngine.RecognizeAsync()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "단일, 비동기 음성 인식 작업을 수행합니다."
  remarks: "이 메서드는 단일, 비동기 인식 작업을 수행합니다. 인식기에서의 로드 하 고 사용할 음성 인식 문법에 대해 작업을 수행합니다.       인식기에서이 메서드를 호출 하는 동안 다음과 같은 이벤트를 발생 수:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  인식기에서 음성으로 식별할 수 있는 입력을 감지할 때 발생 합니다.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  입력 현재 문법 중 하 나와 일치 상태가 모호를 만들 때 발생 합니다.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> 인식기에서 인식 작업을 종료 하는 경우 발생 합니다.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> 발생 시기는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>작업을 완료 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       비동기 인식 작업의 결과 검색 하려면 인식기를 이벤트 처리기를 연결 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>이벤트.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> 인식기에서 인식 동기 또는 비동기 작업을 성공적으로 완료 될 때마다이 이벤트를 발생 시킵니다. 인식 하지 못한 경우는 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>속성 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>이벤트의 처리기에서 액세스할 수 있는 개체는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>이벤트가, `null`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>       동기 인식 기능을 수행 하려면 중 하나를 사용는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic asynchronous speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one asynchronous recognition operation. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create a grammar for choosing cities for a flight.  \n        Choices cities = new Choices(new string[]   \n        { \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I want to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Construct a Grammar object and load it to the recognizer.  \n        Grammar cityChooser = new Grammar(gb);  \n        cityChooser.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(cityChooser);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer and start an asynchronous  \n        // recognition operation.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        completed = false;  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        recognizer.RecognizeAsync();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n        Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsync ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  id: RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsync(RecognizeMode)
  nameWithType: SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "하나 이상의 비동기 음성 인식 작업을 수행합니다."
  remarks: "경우 `mode` 은 <xref:System.Speech.Recognition.RecognizeMode>, 인식기에서 계속 될 때까지 비동기 인식 작업을 수행는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>메서드를 호출 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A> </xref:System.Speech.Recognition.RecognizeMode>       인식기에서이 메서드를 호출 하는 동안 다음과 같은 이벤트를 발생 수:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  인식기에서 음성으로 식별할 수 있는 입력을 감지할 때 발생 합니다.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  입력 현재 문법 중 하 나와 일치 상태가 모호를 만들 때 발생 합니다.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> 인식기에서 인식 작업을 종료 하는 경우 발생 합니다.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> 발생 시기는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>작업을 완료 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       비동기 인식 작업의 결과 검색 하려면 인식기를 이벤트 처리기를 연결 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>이벤트.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> 인식기에서 인식 동기 또는 비동기 작업을 성공적으로 완료 될 때마다이 이벤트를 발생 시킵니다. 인식 하지 못한 경우는 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>속성 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>이벤트의 처리기에서 액세스할 수 있는 개체는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>이벤트가, `null`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>       비동기 인식 작업은 다음과 같은 이유로 실패할 수 있습니다.-에 대 한 시간 제한 간격이 만료 되기 전에 음성 인식 되지 않습니다는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -인식 엔진 음성 검색 했지만 로드 및 사용에 일치 하는 항목을 찾은 <xref:System.Speech.Recognition.Grammar>개체입니다.</xref:System.Speech.Recognition.Grammar>       동기 인식 기능을 수행 하려면 중 하나를 사용는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic asynchronous speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs multiple asynchronous recognition operations. The asynchronous operations are cancelled after 30 seconds. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create a grammar for choosing cities for a flight.  \n        Choices cities = new Choices(new string[] { \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I want to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Construct a Grammar object and load it to the recognizer.  \n        Grammar cityChooser = new Grammar(gb);  \n        cityChooser.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(cityChooser);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer and start asynchronous  \n        // recognition.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        completed = false;  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 30 seconds, and then cancel asynchronous recognition.  \n        Thread.Sleep(TimeSpan.FromSeconds(30));  \n        recognizer.RecognizeAsyncCancel();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n        Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsync (System.Speech.Recognition.RecognizeMode mode);
    parameters:
    - id: mode
      type: System.Speech.Recognition.RecognizeMode
      description: "하나 또는 여러 개의 인식 작업을 수행할 것인지 여부를 나타냅니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  id: RecognizeAsyncCancel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsyncCancel()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "비동기 인식 현재 인식 작업을 완료 될 때까지 기다리지 않고 종료 합니다."
  remarks: "이 메서드는 비동기 인식을 즉시 종료합니다. 현재 비동기 인식 작업 입력을 받고, 입력 잘리고 기존 입력을 사용 하면 작업이 완료 됩니다. 인식기 발생은 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>비동기 작업이 취소 되 고 설정 하는 경우 이벤트는 <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A>속성은 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>를 `true`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> 시작 된 비동기 작업을 취소 하는이 메서드는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       비동기 인식 된 입력을 자르지 않고을 중지 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the use of the RecognizeAsyncCancel method. The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it cancels the operation. The recognizer receives input from the file, c:\\temp\\audioinput\\sample.wav. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Begin asynchronous recognition from pre-recorded input.  \n        recognizer.SetInputToWaveFile(@\"c:\\temp\\audioinput\\sample.wav\");  \n  \n        completed = false;  \n        Console.WriteLine(\"Begin continuing asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 2 seconds and then cancel the recognition operation.  \n        Thread.Sleep(TimeSpan.FromSeconds(2));  \n        recognizer.RecognizeAsyncCancel();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\" - asynchronous operation canceled.\");  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void RecognizeAsyncCancel ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  id: RecognizeAsyncStop
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsyncStop()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "비동기 인식 현재 인식 작업이 완료 된 후에 중지 합니다."
  remarks: "이 메서드는 입력을 자르지 않고 비동기 인식을 종료 합니다. 현재 비동기 인식 작업 입력을 받고, 인식기에서 입력을 현재 인식 작업이 완료 될 때까지 적용 계속 됩니다. 인식기 발생은 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>비동기 작업이 중지 되 고 설정 하는 경우 이벤트는 <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A>속성의는 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>를 `true`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> 시작 된 비동기 작업을 중지 하는이 메서드는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       비동기 인식 기존 입력만 즉시 취소 하려면 사용 하 여는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the use of the RecognizeAsyncStop method. The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it stops the operation. The recognizer receives input from the file, c:\\temp\\audioinput\\sample.wav. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Begin asynchronous recognition from pre-recorded input.  \n        recognizer.SetInputToWaveFile(@\"c:\\temp\\audioinput\\sample.wav\");  \n  \n        completed = false;  \n        Console.WriteLine(\"Begin continuing asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 2 seconds and then stop the recognition operation.  \n        Thread.Sleep(TimeSpan.FromSeconds(2));  \n        recognizer.RecognizeAsyncStop();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\" - asynchronous operation canceled.\");  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsyncStop ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  id: RecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeCompleted
  nameWithType: SpeechRecognitionEngine.RecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "발생 시기는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 비동기 인식 작업을 종료 합니다."
  remarks: "<xref:System.Speech.Recognition.SpeechRecognitionEngine>개체의 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>메서드는 비동기 인식 작업을 시작 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine> 인식기에서 비동기 작업을 완료 하는 경우이 이벤트를 발생 시킵니다.       RecognizeCompleted 이벤트에 대 한 처리기를 사용, 액세스할 수 있습니다는 <xref:System.Speech.Recognition.RecognitionResult>에 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>개체입니다.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognitionResult> 인식 하지 못한 경우, <xref:System.Speech.Recognition.RecognitionResult>됩니다 `null`.</xref:System.Speech.Recognition.RecognitionResult> 시간 제한 또는 중단에 오디오 입력 실패 인식 원인 인지를 확인 하려면에 대 한 속성에 액세스할 수 있습니다 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A>, 또는 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A>.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A>       참조는 <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>클래스에 대 한 자세한 내용은.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs>       최상의 거부 된 인식 후보에 대 한 세부 정보를 가져오려면 연결에 대 한 처리기는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>이벤트.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>       RecognizeCompleted 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the RecognizeCompleted event to display information about the results of recognition in the console.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \n        recognizer.LoadGrammarCompleted +=   \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted, error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"RecognizeCompleted:\");  \n        Console.WriteLine(\"  Grammar: \" + e.Result.Grammar.Name);  \n        Console.WriteLine(\"  Recognized text: \" + e.Result.Text);  \n        Console.WriteLine(\"  Confidence score: \" + e.Result.Confidence);  \n        Console.WriteLine(\"  Audio position: \" + e.AudioPosition);  \n      }  \n  \n      else  \n      {  \n        Console.WriteLine(\"RecognizeCompleted: No result.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded:  \" + e.Grammar.Name);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs> RecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizeCompletedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  id: RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "현재 위치를 가져옵니다는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 처리 하는 오디오 입력에서 합니다."
  remarks: "오디오 위치는 각 음성 인식기 관련이 있습니다. 활성화 되 면 입력 스트림의&0; 값은 설정 됩니다.       RecognizerAudioPosition 속성 참조는 <xref:System.Speech.Recognition.SpeechRecognitionEngine>오디오 입력 내에서 개체의 위치입니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine> 반면,는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>속성 참조의 생성 된 오디오 스트림 내의 위치를 입력된 장치.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> 이 위치는 다를 수 있습니다. 예를 들어 인식기에서 받는 경우 하지는 자신이 입력 하면서도 RecognizerAudioPosition 속성의 값은의 값 보다 작은 인식 결과 생성 되는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>"
  syntax:
    content: public TimeSpan RecognizerAudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "인식기에 오디오 입력을 처리 하는 위치입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  id: RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "현재 인스턴스에 대 한 정보를 가져옵니다 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>합니다."
  remarks: "현재 시스템에 대 한 모든 설치 된 음성 인식기에 대 한 정보를 가져오려면는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>"
  example:
  - "The following example gets a partial list of data for the current in-process speech recognition engine. For more information, see <xref:System.Speech.Recognition.RecognizerInfo>.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognitionEngine  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer = new SpeechRecognitionEngine())  \n      {  \n        Console.WriteLine(\"Information for the current speech recognition engine:\");  \n        Console.WriteLine(\"  Name: {0}\", recognizer.RecognizerInfo.Name);  \n        Console.WriteLine(\"  Culture: {0}\", recognizer.RecognizerInfo.Culture.ToString());  \n        Console.WriteLine(\"  Description: {0}\", recognizer.RecognizerInfo.Description);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }
    return:
      type: System.Speech.Recognition.RecognizerInfo
      description: "현재 음성 인식기에 대 한 정보입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  id: RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognitionEngine.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "실행 될 때 발생 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 수정 작업을 허용 하도록 일시 중지 합니다."
  remarks: "응용 프로그램 사용 해야 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>를 실행 중인 인스턴스 일시 중지 <xref:System.Speech.Recognition.SpeechRecognitionEngine>해당 설정을 수정 하기 전에 해당 또는 <xref:System.Speech.Recognition.Grammar>개체.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine>수정을 수락할 준비가 되었을 때이 이벤트를 발생 시킵니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine>       예를 들어 동안는 <xref:System.Speech.Recognition.SpeechRecognitionEngine>는 일시 중지 된 있습니다 수 로드, 언로드, 설정 및 해제 <xref:System.Speech.Recognition.Grammar>개체, 및에 대 한 값을 수정는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> 자세한 내용은 참조는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       RecognizerUpdateReached 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for RecognizerUpdateReached event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and configure its input.  \n      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create the first grammar - Farm.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n  \n        // Create the second grammar - Fruit.  \n        Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n        GrammarBuilder favorite = new GrammarBuilder(fruit);  \n        Grammar favoriteFruit = new Grammar(favorite);  \n        favoriteFruit.Name = \"Fruit\";  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizerUpdateReached +=  \n          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the Farm grammar.  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n        Console.WriteLine(\"Starting asynchronous, continuous recognition\");  \n        Console.WriteLine(\"  Farm grammar is loaded and enabled.\");  \n  \n        // Pause to recognize farm animals.  \n        Thread.Sleep(7000);  \n        Console.WriteLine();  \n  \n        // Request an update and load the Fruit grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.LoadGrammarAsync(favoriteFruit);  \n        Thread.Sleep(7000);  \n  \n        // Request an update and unload the Farm grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.UnloadGrammar(farmAnimals);  \n        Thread.Sleep(7000);  \n      }  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  {0} grammar is loaded and {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Speech recognized: \" + e.Result.Text);  \n    }  \n  \n    // Write a message to the console when recognition fails.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Recognition attempt failed\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs> RecognizerUpdateReached;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  id: RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "요청을 인식기에서 업데이트의 상태를 일시 중지할 수입니다."
  remarks: "인식기에서 생성 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>이벤트는 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>속성은 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>은 `null`.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>       사용자 토큰을 제공 하기 위해 사용 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> 오디오 위치 오프셋을 지정 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>"
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the RequestRecognizerUpdate method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and configure its input.  \n      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create the first grammar - Farm.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n  \n        // Create the second grammar - Fruit.  \n        Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n        GrammarBuilder favorite = new GrammarBuilder(fruit);  \n        Grammar favoriteFruit = new Grammar(favorite);  \n        favoriteFruit.Name = \"Fruit\";  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizerUpdateReached +=  \n          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the Farm grammar.  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n        Console.WriteLine(\"Starting asynchronous, continuous recognition\");  \n        Console.WriteLine(\"  Farm grammar is loaded and enabled.\");  \n  \n        // Pause to recognize farm animals.  \n        Thread.Sleep(7000);  \n        Console.WriteLine();  \n  \n        // Request an update and load the Fruit grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.LoadGrammarAsync(favoriteFruit);  \n        Thread.Sleep(7000);  \n  \n        // Request an update and unload the Farm grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.UnloadGrammar(farmAnimals);  \n        Thread.Sleep(7000);  \n      }  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  {0} grammar is loaded and {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Speech recognized: \" + e.Result.Text);  \n    }  \n  \n    // Write a message to the console when recognition fails.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Recognition attempt failed\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RequestRecognizerUpdate ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  id: RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "요청 인식기의 상태를 업데이트 하려면 일시 중지 하 고 연결된 된 이벤트에 대 한 사용자 토큰을 제공 합니다."
  remarks: "인식기에서 생성 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>이벤트에는 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>의 속성은 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>의 값을 포함는 `userToken` 매개 변수.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>       오디오 위치 오프셋을 지정 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken);
    parameters:
    - id: userToken
      type: System.Object
      description: "작업에 대 한 정보를 포함 하는 사용자 정의 정보입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  id: RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "요청 인식기의 상태를 업데이트 하려면 일시 중지 하 고 연결된 된 이벤트에 대 한 오프셋 및 사용자 토큰을 제공 합니다."
  remarks: "인식기에서 인식기 될 때까지 인식기 업데이트 요청을 시작 하지 않고 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>현재 equals <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>플러스 `audioPositionAheadToRaiseUpdate`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>       인식기에서 생성 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>이벤트에는 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>의 속성은 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>의 값을 포함는 `userToken` 매개 변수.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);
    parameters:
    - id: userToken
      type: System.Object
      description: "작업에 대 한 정보를 포함 하는 사용자 정의 정보입니다."
    - id: audioPositionAheadToRaiseUpdate
      type: System.TimeSpan
      description: "현재에서 오프셋 <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*>요청 지연.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*>"
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  id: SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "구성에서 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 입력 오디오 스트림을 받을 개체입니다."
  remarks: "인식기에서 인식 작업 하는 동안 입력 스트림의 끝에 도달 하는 경우 사용 가능한 입력으로 인식 작업을 종료 합니다. 인식기에 대 한 입력을 업데이트 하지 않는 한 모든 후속 인식 작업에서 예외를 생성할 수 있습니다."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses input from an audio file, example.wav, that contains the phrases, \"testing testing one two three\" and \"mister cooper\", separated by a pause. The example generates the following output.  \n  \n```  \n  \nStarting asynchronous recognition...  \n  Recognized text =  Testing testing 123  \n  Recognized text =  Mr. Cooper  \n  End of stream encountered.  \nDone.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.IO;  \nusing System.Speech.AudioFormat;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace InputExamples  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Configure the input to the recognizer.  \n        recognizer.SetInputToAudioStream(  \n          File.OpenRead(@\"c:\\temp\\audioinput\\example.wav\"),  \n          new SpeechAudioFormatInfo(  \n            44100, AudioBitsPerSample.Sixteen, AudioChannel.Mono));  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Perform recognition of the whole file.  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  Error encountered, {0}: {1}\",  \n          e.Error.GetType().Name, e.Error.Message);  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(\"  End of stream encountered.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void SetInputToAudioStream (System.IO.Stream audioSource, System.Speech.AudioFormat.SpeechAudioFormatInfo audioFormat);
    parameters:
    - id: audioSource
      type: System.IO.Stream
      description: "오디오 입력된 스트림입니다."
    - id: audioFormat
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "오디오 입력의 형식입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  id: SetInputToDefaultAudioDevice
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToDefaultAudioDevice()
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "구성에서 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 기본 오디오 장치에서 입력을 받을 개체입니다."
  remarks: ''
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses output from the default audio device, performs multiple, asynchronous recognition operations, and exits when a user utters the phrase, \"exit\".  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace DefaultInput  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition has finished.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load the exit grammar.  \n        Grammar exitGrammar = new Grammar(new GrammarBuilder(\"exit\"));  \n        exitGrammar.Name = \"Exit Grammar\";  \n        recognizer.LoadGrammar(exitGrammar);  \n  \n        // Create and load the dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers to the recognizer.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Begin asynchronous recognition.  \n        Console.WriteLine(\"Starting recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait for recognition to finish.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized:\");  \n      string grammarName = \"<not available>\";  \n      if (e.Result.Grammar.Name != null &&  \n        !e.Result.Grammar.Name.Equals(string.Empty))  \n      {  \n        grammarName = e.Result.Grammar.Name;  \n      }  \n      Console.WriteLine(\"    {0,-17} - {1}\",  \n        grammarName, e.Result.Text);  \n  \n      if (grammarName.Equals(\"Exit Grammar\"))  \n      {  \n        ((SpeechRecognitionEngine)sender).RecognizeAsyncCancel();  \n      }  \n    }  \n  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Recognition completed.\");  \n      completed = true;  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void SetInputToDefaultAudioDevice ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  id: SetInputToNull
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToNull()
  nameWithType: SpeechRecognitionEngine.SetInputToNull()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기에 대 한 입력을 사용 하지 않도록 설정 합니다."
  remarks: "구성에서 <xref:System.Speech.Recognition.SpeechRecognitionEngine>사용 하는 경우 입력에 대 한 개체는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>메서드를 일시적으로 오프 라인 인식 엔진을 가져올 때 또는.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine>"
  syntax:
    content: public void SetInputToNull ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  id: SetInputToWaveFile(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToWaveFile(String)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "구성에서 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 파형 오디오 (.wav) 형식 파일에서 입력을 받을 개체입니다."
  remarks: "인식기에서 인식 작업 하는 동안 입력된 파일의 끝에 도달 하는 경우 사용 가능한 입력으로 인식 작업을 종료 합니다. 인식기에 대 한 입력을 업데이트 하지 않는 한 모든 후속 인식 작업에서 예외를 생성할 수 있습니다."
  example:
  - "The following example performs recognition on the audio in a .wav file and writes the recognized text to the console.  \n  \n```  \nusing System;  \nusing System.IO;  \nusing System.Speech.Recognition;  \nusing System.Speech.AudioFormat;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Configure the input to the recognizer.  \nrecognizer.SetInputToWaveFile(@\"c:\\temp\\SampleWAVInput.wav\");  \n  \n        // Attach event handlers for the results of recognition.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizeCompleted +=   \n          new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \n  \n        // Perform recognition on the entire file.  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        while (!completed)  \n        {  \n          Console.ReadLine();  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  Error encountered, {0}: {1}\",  \n        e.Error.GetType().Name, e.Error.Message);  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(\"  End of stream encountered.\");  \n      }  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void SetInputToWaveFile (string path);
    parameters:
    - id: path
      type: System.String
      description: "입력으로 사용할 파일의 경로입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  id: SetInputToWaveStream(System.IO.Stream)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToWaveStream(Stream)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "구성에서 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 파형 오디오 (.wav) 형식 데이터가 포함 된 스트림에서 입력을 받을 개체입니다."
  remarks: "인식기에서 인식 작업 하는 동안 입력 스트림의 끝에 도달 하는 경우 사용 가능한 입력으로 인식 작업을 종료 합니다. 인식기에 대 한 입력을 업데이트 하지 않는 한 모든 후속 인식 작업에서 예외를 생성할 수 있습니다."
  syntax:
    content: public void SetInputToWaveStream (System.IO.Stream audioSource);
    parameters:
    - id: audioSource
      type: System.IO.Stream
      description: "오디오 데이터를 포함 하는 스트림."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  id: SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechDetected
  nameWithType: SpeechRecognitionEngine.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "발생 시기는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 음성으로 식별할 수 있는 입력을 검색 합니다."
  remarks: "음성 인식기 각 대기 및 음성 간을 서로 구별 하는 알고리즘을 있습니다. 경우는 <xref:System.Speech.Recognition.SpeechRecognitionEngine>음성 인식 작업을 수행 하면 해당 알고리즘으로 음성 입력을 식별 하는 경우 SpeechDetected 이벤트를 발생 시킵니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine> <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A>속성은 연결 된 <xref:System.Speech.Recognition.SpeechDetectedEventArgs>개체는 인식기에서 음성을 검색할 입력 스트림의 위치를 나타냅니다.</xref:System.Speech.Recognition.SpeechDetectedEventArgs> </xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine>SpeechDetected 이벤트의 발생 하기 전까지 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>, 또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>이벤트.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine>       자세한 내용은 참조는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>       SpeechDetected 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example is part of a console application for choosing origin and destination cities for a flight. The application recognizes phrases such as \"I want to fly from Miami to Chicago.\"  The example uses the SpeechDetected event to report the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> each time speech is detected.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create a grammar.  \n        Choices cities = new Choices(new string[] {   \n          \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I would like to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Create a Grammar object and load it to the recognizer.  \n        Grammar g = new Grammar(gb);  \n        g.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(g);  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech detected at AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs> SpeechDetected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  id: SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechHypothesized
  nameWithType: SpeechRecognitionEngine.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "발생 시기는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 에서의 문법에 여러 전체 구 구성 될 수 있는 단어를 인식 합니다."
  remarks: "<xref:System.Speech.Recognition.SpeechRecognitionEngine>입력된 구를 식별 하려고 하는 대로 다양 한 SpeechHypothesized 이벤트를 생성 합니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine> 부분적으로 인식 된 구의 텍스트에 액세스할 수 있습니다는 <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>의 속성은 <xref:System.Speech.Recognition.SpeechHypothesizedEventArgs>SpeechHypothesized 이벤트에 대 한 처리기에서 개체입니다.</xref:System.Speech.Recognition.SpeechHypothesizedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> 일반적으로 이러한 이벤트를 처리는 디버깅에 대해서만 유용 합니다.       <xref:System.Speech.Recognition.SpeechHypothesizedEventArgs><xref:System.Speech.Recognition.RecognitionEventArgs>.</xref:System.Speech.Recognition.RecognitionEventArgs> 에서 파생</xref:System.Speech.Recognition.SpeechHypothesizedEventArgs>       자세한 내용은 참조는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>속성 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>       SpeechHypothesized 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\". The example uses the SpeechHypothesized event to display incomplete phrase fragments in the console as they are recognized.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display the list of\");  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\");  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\");  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech hypothesized: \" + e.Result.Text);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine();   \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs> SpeechHypothesized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  id: SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "발생 시기는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 의 로드 및 사용 하도록 설정 하는 중 일치 하지 않는 입력을 받는 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> 개체입니다."
  remarks: "인식기 인지는 입력와 일치 하지 않으므로 충분 한 신뢰 된 로드 및 사용 하도록 설정 하는 경우이 이벤트를 발생 시킵니다 <xref:System.Speech.Recognition.Grammar>개체입니다.</xref:System.Speech.Recognition.Grammar> <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>의 속성은 <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>거부 된 포함 <xref:System.Speech.Recognition.RecognitionResult>개체입니다.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> SpeechRecognitionRejected 이벤트에 대 한 처리기를 사용 하 여 인식 검색할 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>는 거부 된 및 해당 <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>점수.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       응용 프로그램을 사용 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognitionEngine>인스턴스, 입력은 음성 승인 또는 거부 중 하나가 지정 된 신뢰 수준을 수정할 수 있습니다는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine> 음성 인식 아닌 음성을 사용 하 여 입력에 반응 하는 방법을 수정할 수는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>       SpeechRecognitionRejected 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the SpeechRecognitionRejected event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> to produce a successful recognition. The handler also displays recognition result <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> that were rejected because of low confidence scores.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech input was rejected.\");  \n      foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n      {  \n      Console.WriteLine(\"  Rejected phrase: \" + phrase.Text);  \n      Console.WriteLine(\"  Confidence score: \" + phrase.Confidence);  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n      Console.WriteLine(\"  Confidence score: \" + e.Result.Confidence);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> SpeechRecognitionRejected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  id: SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognized
  nameWithType: SpeechRecognitionEngine.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "발생 시기는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 의 로드 및 활성화 중 하 나와 일치 하는 입력을 받는 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> 개체입니다."
  remarks: "중 하나를 사용 하 여 인식 작업을 시작할 수는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> 인식기에서 입력의 로드 중 하나를 일치 하는지 결정 하는 경우는 SpeechRecognized 이벤트를 발생 시킨 <xref:System.Speech.Recognition.Grammar>개체는 충분 한 인식을 구성 하는 신뢰 수준으로 됩니다.</xref:System.Speech.Recognition.Grammar> <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>의 속성은 <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>허용 포함 <xref:System.Speech.Recognition.RecognitionResult>개체입니다.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> SpeechRecognized 이벤트의 처리기를 인식된 된 구와 뿐만 아니라 인식의 목록을 가져올 수 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>낮은 신뢰성 점수와.</xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       응용 프로그램을 사용 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognitionEngine>인스턴스, 입력은 음성 승인 또는 거부 중 하나가 지정 된 신뢰 수준을 수정할 수 있습니다는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine>  음성 인식 아닌 음성을 사용 하 여 입력에 반응 하는 방법을 수정할 수는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>속성.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>       인식기 문법, 일치 하는 입력을 받을 때의 <xref:System.Speech.Recognition.Grammar>개체가 발생 시킬 수는 <xref:System.Speech.Recognition.Grammar.SpeechRecognized>이벤트.</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar> <xref:System.Speech.Recognition.Grammar>개체의 <xref:System.Speech.Recognition.Grammar.SpeechRecognized>음성 인식기 SpeechRecognized 이벤트 보다 먼저 발생 합니다.</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar> 에 대 한 처리기가 항상 특정 문법에 관련 된 모든 태스크를 수행 해야는 <xref:System.Speech.Recognition.Grammar.SpeechRecognized>이벤트.</xref:System.Speech.Recognition.Grammar.SpeechRecognized>       SpeechRecognized 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example is part of a console application that creates speech recognition grammar, constructs a <xref:System.Speech.Recognition.Grammar> object, and loads it into the <xref:System.Speech.Recognition.SpeechRecognitionEngine> to perform recognition. The example demonstrates speech input to a <xref:System.Speech.Recognition.SpeechRecognitionEngine>, the associated recognition results, and the associated events raised by the speech recognizer.  \n  \n Spoken input such as \"I want to fly from Chicago to Miami\" will trigger a SpeechRecognized event. Speaking the phrase \"Fly me from Houston to Chicago \" will not trigger a SpeechRecognized event.  \n  \n The example uses a handler for the SpeechRecognized event to display successfully recognized phrases and the semantics they contain in the console.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer = new SpeechRecognitionEngine())  \n      {  \n  \n        // Create SemanticResultValue objects that contain cities and airport codes.  \n        SemanticResultValue chicago = new SemanticResultValue(\"Chicago\", \"ORD\");  \n        SemanticResultValue boston = new SemanticResultValue(\"Boston\", \"BOS\");  \n        SemanticResultValue miami = new SemanticResultValue(\"Miami\", \"MIA\");  \n        SemanticResultValue dallas = new SemanticResultValue(\"Dallas\", \"DFW\");  \n  \n        // Create a Choices object and add the SemanticResultValue objects, using  \n        // implicit conversion from SemanticResultValue to GrammarBuilder  \n        Choices cities = new Choices();  \n        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  \n  \n        // Build the phrase and add SemanticResultKeys.  \n        GrammarBuilder chooseCities = new GrammarBuilder();  \n        chooseCities.Append(\"I want to fly from\");  \n        chooseCities.Append(new SemanticResultKey(\"origin\", cities));  \n        chooseCities.Append(\"to\");  \n        chooseCities.Append(new SemanticResultKey(\"destination\", cities));  \n  \n        // Build a Grammar object from the GrammarBuilder.  \n        Grammar bookFlight = new Grammar(chooseCities);  \n        bookFlight.Name = \"Book Flight\";  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(bookFlight);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized:  \" + e.Result.Text);  \n      Console.WriteLine();  \n      Console.WriteLine(\"Semantic results:\");  \n      Console.WriteLine(\"  The flight origin is \" + e.Result.Semantics[\"origin\"].Value);  \n      Console.WriteLine(\"  The flight destination is \" + e.Result.Semantics[\"destination\"].Value);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs> SpeechRecognized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  id: UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "모두 언로드합니다 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> 인식기에서 개체입니다."
  remarks: "현재 인식기를 로드 하는 경우는 <xref:System.Speech.Recognition.Grammar>이 이렇게 될 때까지 대기 하는 비동기적으로 <xref:System.Speech.Recognition.Grammar>모든 언로드합니다 되기 전에 로드 됩니다는 <xref:System.Speech.Recognition.Grammar>에서 개체는 <xref:System.Speech.Recognition.SpeechRecognitionEngine>인스턴스.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.Grammar>       사용 하 여 특정 문법을 언로드하려면는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.  \n  \n```  \nLoading grammars...  \nLoaded grammars:  \n - Grammar1  \n - Grammar2  \n - Grammar3  \n  \nUnloading Grammar1...  \nLoaded grammars:  \n - Grammar2  \n - Grammar3  \n  \nUnloading all grammars...  \nNo grammars loaded.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace UnloadGrammars  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Loading grammars...\");  \n  \n        // Create and load a number of grammars.  \n        Grammar grammar1 = new Grammar(new GrammarBuilder(\"first grammar\"));  \n        grammar1.Name = \"Grammar1\";  \n        recognizer.LoadGrammar(grammar1);  \n  \n        Grammar grammar2 = new Grammar(new GrammarBuilder(\"second grammar\"));  \n        grammar2.Name = \"Grammar2\";  \n        recognizer.LoadGrammar(grammar2);  \n  \n        Grammar grammar3 = new Grammar(new GrammarBuilder(\"third grammar\"));  \n        grammar3.Name = \"Grammar3\";  \n        recognizer.LoadGrammar(grammar3);  \n  \n        // List the recognizer's loaded grammars.  \n        ListGrammars(recognizer);  \n  \n        // Unload one grammar and list the loaded grammars.  \n        Console.WriteLine(\"Unloading Grammar1...\");  \n        recognizer.UnloadGrammar(grammar1);  \n        ListGrammars(recognizer);  \n  \n        // Unload all grammars and list the loaded grammars.  \n        Console.WriteLine(\"Unloading all grammars...\");  \n        recognizer.UnloadAllGrammars();  \n        ListGrammars(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListGrammars(SpeechRecognitionEngine recognizer)  \n    {  \n      // Make a copy of the recognizer's grammar collection.  \n      List<Grammar> loadedGrammars = new List<Grammar>(recognizer.Grammars);  \n  \n      if (loadedGrammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in recognizer.Grammars)  \n        {  \n          Console.WriteLine(\" - {0}\", g.Name);  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void UnloadAllGrammars ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  id: UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "지정 된 언로드합니다 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> 에서 개체는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 인스턴스."
  remarks: "응용 프로그램을 사용 해야 인식기에서 실행 중인 경우 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>일시 중지 하는 <xref:System.Speech.Recognition.SpeechRecognitionEngine>로드, 언로드, 활성화 또는 비활성화 하기 전에 인스턴스는 <xref:System.Speech.Recognition.Grammar>개체입니다.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> 모든 언로드 <xref:System.Speech.Recognition.Grammar>개체를 사용 하 여는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.Grammar>"
  example:
  - "The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.  \n  \n```  \nLoading grammars...  \nLoaded grammars:  \n - Grammar1  \n - Grammar2  \n - Grammar3  \n  \nUnloading Grammar1...  \nLoaded grammars:  \n - Grammar2  \n - Grammar3  \n  \nUnloading all grammars...  \nNo grammars loaded.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace UnloadGrammars  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Loading grammars...\");  \n  \n        // Create and load a number of grammars.  \n        Grammar grammar1 = new Grammar(new GrammarBuilder(\"first grammar\"));  \n        grammar1.Name = \"Grammar1\";  \n        recognizer.LoadGrammar(grammar1);  \n  \n        Grammar grammar2 = new Grammar(new GrammarBuilder(\"second grammar\"));  \n        grammar2.Name = \"Grammar2\";  \n        recognizer.LoadGrammar(grammar2);  \n  \n        Grammar grammar3 = new Grammar(new GrammarBuilder(\"third grammar\"));  \n        grammar3.Name = \"Grammar3\";  \n        recognizer.LoadGrammar(grammar3);  \n  \n        // List the recognizer's loaded grammars.  \n        ListGrammars(recognizer);  \n  \n        // Unload one grammar and list the loaded grammars.  \n        Console.WriteLine(\"Unloading Grammar1...\");  \n        recognizer.UnloadGrammar(grammar1);  \n        ListGrammars(recognizer);  \n  \n        // Unload all grammars and list the loaded grammars.  \n        Console.WriteLine(\"Unloading all grammars...\");  \n        recognizer.UnloadAllGrammars();  \n        ListGrammars(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListGrammars(SpeechRecognitionEngine recognizer)  \n    {  \n      // Make a copy of the recognizer's grammar collection.  \n      List<Grammar> loadedGrammars = new List<Grammar>(recognizer.Grammars);  \n  \n      if (loadedGrammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in recognizer.Grammars)  \n        {  \n          Console.WriteLine(\" - {0}\", g.Name);  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "언로드할 문법 개체입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "이 인식기에 문법을 로드 되지 않은 또는이 인식기 문법 비동기적으로 로드 중인 합니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  id: UpdateRecognizerSetting(System.String,System.Int32)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UpdateRecognizerSetting(String,Int32)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "지정된 된 설정에 대 한 업데이트는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 지정 된 정수 값을 사용 합니다."
  remarks: "제외 `PersistedBackgroundAdaptation`, UpdateRecognizerSetting 메서드를 사용 하 여 설정할 속성 값에 계속 적용만의 현재 인스턴스 <xref:System.Speech.Recognition.SpeechRecognitionEngine>, 기본 설정으로 되돌리기는 후.</xref:System.Speech.Recognition.SpeechRecognitionEngine> 참조 <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>지원 되는 설정에 대 한 설명.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  example:
  - "The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale. The example updates the confidence level settings, and then queries the recognizer to check the updated values. The example generates the following output.  \n  \n```  \nSettings for recognizer MS-1033-80-DESK:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 150  \n  ComplexResponseSpeed           = 500  \n  AdaptationOn                   = 1  \n  PersistedBackgroundAdaptation  = 1  \n  \nUpdated settings:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 200  \n  ComplexResponseSpeed           = 300  \n  AdaptationOn                   = 0  \n  PersistedBackgroundAdaptation  = 0  \n  \nPress any key to exit...  \n```  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognizerSettings  \n{  \n  class Program  \n  {  \n    static readonly string[] settings = new string[] {  \n      \"ResourceUsage\",  \n      \"ResponseSpeed\",  \n      \"ComplexResponseSpeed\",  \n      \"AdaptationOn\",  \n      \"PersistedBackgroundAdaptation\",  \n    };  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Settings for recognizer {0}:\",  \n          recognizer.RecognizerInfo.Name);  \n        Console.WriteLine();  \n  \n        // List the current settings.  \n        ListSettings(recognizer);  \n  \n        // Change some of the settings.  \n        recognizer.UpdateRecognizerSetting(\"ResponseSpeed\", 200);  \n        recognizer.UpdateRecognizerSetting(\"ComplexResponseSpeed\", 300);  \n        recognizer.UpdateRecognizerSetting(\"AdaptationOn\", 1);  \n        recognizer.UpdateRecognizerSetting(\"PersistedBackgroundAdaptation\", 0);  \n  \n        Console.WriteLine(\"Updated settings:\");  \n        Console.WriteLine();  \n  \n        // List the updated settings.  \n        ListSettings(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListSettings(SpeechRecognitionEngine recognizer)  \n    {  \n      foreach (string setting in settings)  \n      {  \n        try  \n        {  \n          object value = recognizer.QueryRecognizerSetting(setting);  \n          Console.WriteLine(\"  {0,-30} = {1}\", setting, value);  \n        }  \n        catch  \n        {  \n          Console.WriteLine(\"  {0,-30} is not supported by this recognizer.\",  \n            setting);  \n        }  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void UpdateRecognizerSetting (string settingName, int updatedValue);
    parameters:
    - id: settingName
      type: System.String
      description: "업데이트 설정의 이름입니다."
    - id: updatedValue
      type: System.Int32
      description: "설정에 대해 새 값입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>가 빈 문자열 (&quot;&quot;)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "해당 이름의 인식기 설정을 않아도 됩니다."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  id: UpdateRecognizerSetting(System.String,System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UpdateRecognizerSetting(String,String)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "지정된 된 문자열 값으로 지정 된 음성 인식 엔진 설정을 업데이트합니다."
  remarks: "제외 `PersistedBackgroundAdaptation`, UpdateRecognizerSetting 메서드를 사용 하 여 설정할 속성 값에 계속 적용만의 현재 인스턴스 <xref:System.Speech.Recognition.SpeechRecognitionEngine>, 기본 설정으로 되돌리기는 후.</xref:System.Speech.Recognition.SpeechRecognitionEngine> 참조 <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>지원 되는 설정에 대 한 설명.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  syntax:
    content: public void UpdateRecognizerSetting (string settingName, string updatedValue);
    parameters:
    - id: settingName
      type: System.String
      description: "업데이트 설정의 이름입니다."
    - id: updatedValue
      type: System.String
      description: "설정에 대해 새 값입니다."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>가 빈 문자열 (&quot;&quot;)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "해당 이름의 인식기 설정을 않아도 됩니다."
  platform:
  - net462
references:
- uid: System.Object
  isExternal: false
  name: System.Object
- uid: System.ArgumentException
  isExternal: true
  name: System.ArgumentException
- uid: System.ArgumentNullException
  isExternal: true
  name: System.ArgumentNullException
- uid: System.ArgumentOutOfRangeException
  isExternal: true
  name: System.ArgumentOutOfRangeException
- uid: System.InvalidOperationException
  isExternal: true
  name: System.InvalidOperationException
- uid: System.NotSupportedException
  isExternal: true
  name: System.NotSupportedException
- uid: System.OperationCanceledException
  isExternal: true
  name: System.OperationCanceledException
- uid: System.Collections.Generic.KeyNotFoundException
  isExternal: true
  name: System.Collections.Generic.KeyNotFoundException
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine()
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(CultureInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
- uid: System.Globalization.CultureInfo
  parent: System.Globalization
  isExternal: true
  name: CultureInfo
  nameWithType: CultureInfo
  fullName: System.Globalization.CultureInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(RecognizerInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
- uid: System.Speech.Recognition.RecognizerInfo
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerInfo
  nameWithType: RecognizerInfo
  fullName: System.Speech.Recognition.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(String)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(String)
- uid: System.String
  parent: System
  isExternal: true
  name: String
  nameWithType: String
  fullName: System.String
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
- uid: System.Speech.AudioFormat.SpeechAudioFormatInfo
  parent: System.Speech.AudioFormat
  isExternal: false
  name: SpeechAudioFormatInfo
  nameWithType: SpeechAudioFormatInfo
  fullName: System.Speech.AudioFormat.SpeechAudioFormatInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
- uid: System.Int32
  parent: System
  isExternal: true
  name: Int32
  nameWithType: Int32
  fullName: System.Int32
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevelUpdated
  nameWithType: SpeechRecognitionEngine.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
- uid: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioLevelUpdatedEventArgs>
  nameWithType: EventHandler<AudioLevelUpdatedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioLevelUpdatedEventArgs
    name: AudioLevelUpdatedEventArgs
    nameWithType: AudioLevelUpdatedEventArgs
    fullName: AudioLevelUpdatedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
- uid: System.TimeSpan
  parent: System
  isExternal: true
  name: TimeSpan
  nameWithType: TimeSpan
  fullName: System.TimeSpan
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognitionEngine.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
- uid: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioSignalProblemOccurredEventArgs>
  nameWithType: EventHandler<AudioSignalProblemOccurredEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioSignalProblemOccurredEventArgs
    name: AudioSignalProblemOccurredEventArgs
    nameWithType: AudioSignalProblemOccurredEventArgs
    fullName: AudioSignalProblemOccurredEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
- uid: System.Speech.Recognition.AudioState
  parent: System.Speech.Recognition
  isExternal: false
  name: AudioState
  nameWithType: AudioState
  fullName: System.Speech.Recognition.AudioState
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioStateChanged
  nameWithType: SpeechRecognitionEngine.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
- uid: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioStateChangedEventArgs>
  nameWithType: EventHandler<AudioStateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioStateChangedEventArgs
    name: AudioStateChangedEventArgs
    nameWithType: AudioStateChangedEventArgs
    fullName: AudioStateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose()
  nameWithType: SpeechRecognitionEngine.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose(Boolean)
  nameWithType: SpeechRecognitionEngine.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(Boolean)
- uid: System.Boolean
  parent: System
  isExternal: true
  name: Boolean
  nameWithType: Boolean
  fullName: System.Boolean
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String)
- uid: System.Speech.Recognition.RecognitionResult
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.RecognizedWordUnit[]
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit[]
  spec.csharp:
  - uid: System.Speech.Recognition.RecognizedWordUnit
    name: RecognizedWordUnit
    nameWithType: RecognizedWordUnit
    fullName: RecognizedWordUnit[]
  - name: '[]'
    nameWithType: '[]'
    fullName: '[]'
- uid: System.Globalization.CompareOptions
  parent: System.Globalization
  isExternal: true
  name: CompareOptions
  nameWithType: CompareOptions
  fullName: System.Globalization.CompareOptions
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<EmulateRecognizeCompletedEventArgs>
  nameWithType: EventHandler<EmulateRecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.EmulateRecognizeCompletedEventArgs
    name: EmulateRecognizeCompletedEventArgs
    nameWithType: EmulateRecognizeCompletedEventArgs
    fullName: EmulateRecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<Grammar>
  nameWithType: ReadOnlyCollection<Grammar>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.Grammar>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.Grammar
    name: Grammar
    nameWithType: Grammar
    fullName: Grammar
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InstalledRecognizers()
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers()
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizerInfo}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<RecognizerInfo>
  nameWithType: ReadOnlyCollection<RecognizerInfo>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerInfo
    name: RecognizerInfo
    nameWithType: RecognizerInfo
    fullName: RecognizerInfo
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(Grammar)
- uid: System.Speech.Recognition.Grammar
  parent: System.Speech.Recognition
  isExternal: false
  name: Grammar
  nameWithType: Grammar
  fullName: System.Speech.Recognition.Grammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognitionEngine.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
- uid: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<LoadGrammarCompletedEventArgs>
  nameWithType: EventHandler<LoadGrammarCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.LoadGrammarCompletedEventArgs
    name: LoadGrammarCompletedEventArgs
    nameWithType: LoadGrammarCompletedEventArgs
    fullName: LoadGrammarCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: QueryRecognizerSetting(String)
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize()
  nameWithType: SpeechRecognitionEngine.Recognize()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize(TimeSpan)
  nameWithType: SpeechRecognitionEngine.Recognize(TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync()
  nameWithType: SpeechRecognitionEngine.RecognizeAsync()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync(RecognizeMode)
  nameWithType: SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
- uid: System.Speech.Recognition.RecognizeMode
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizeMode
  nameWithType: RecognizeMode
  fullName: System.Speech.Recognition.RecognizeMode
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncCancel()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncStop()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeCompleted
  nameWithType: SpeechRecognitionEngine.RecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.RecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizeCompletedEventArgs>
  nameWithType: EventHandler<RecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizeCompletedEventArgs
    name: RecognizeCompletedEventArgs
    nameWithType: RecognizeCompletedEventArgs
    fullName: RecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognitionEngine.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
- uid: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizerUpdateReachedEventArgs>
  nameWithType: EventHandler<RecognizerUpdateReachedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerUpdateReachedEventArgs
    name: RecognizerUpdateReachedEventArgs
    nameWithType: RecognizerUpdateReachedEventArgs
    fullName: RecognizerUpdateReachedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
- uid: System.IO.Stream
  parent: System.IO
  isExternal: true
  name: Stream
  nameWithType: Stream
  fullName: System.IO.Stream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToDefaultAudioDevice()
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToNull()
  nameWithType: SpeechRecognitionEngine.SetInputToNull()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveFile(String)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveStream(Stream)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(Stream)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechDetected
  nameWithType: SpeechRecognitionEngine.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
- uid: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechDetectedEventArgs>
  nameWithType: EventHandler<SpeechDetectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechDetectedEventArgs
    name: SpeechDetectedEventArgs
    nameWithType: SpeechDetectedEventArgs
    fullName: SpeechDetectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechHypothesized
  nameWithType: SpeechRecognitionEngine.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
- uid: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechHypothesizedEventArgs>
  nameWithType: EventHandler<SpeechHypothesizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechHypothesizedEventArgs
    name: SpeechHypothesizedEventArgs
    nameWithType: SpeechHypothesizedEventArgs
    fullName: SpeechHypothesizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognitionRejectedEventArgs>
  nameWithType: EventHandler<SpeechRecognitionRejectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognitionRejectedEventArgs
    name: SpeechRecognitionRejectedEventArgs
    nameWithType: SpeechRecognitionRejectedEventArgs
    fullName: SpeechRecognitionRejectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognized
  nameWithType: SpeechRecognitionEngine.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognizedEventArgs>
  nameWithType: EventHandler<SpeechRecognizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognizedEventArgs
    name: SpeechRecognizedEventArgs
    nameWithType: SpeechRecognizedEventArgs
    fullName: SpeechRecognizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(Grammar)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting(String,Int32)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting(String,String)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose
  nameWithType: SpeechRecognitionEngine.Dispose
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize
  nameWithType: SpeechRecognitionEngine.EmulateRecognize
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InstalledRecognizers
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammar
  nameWithType: SpeechRecognitionEngine.LoadGrammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarAsync
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: QueryRecognizerSetting
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize
  nameWithType: SpeechRecognitionEngine.Recognize
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync
  nameWithType: SpeechRecognitionEngine.RecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncCancel
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncStop
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToAudioStream
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToDefaultAudioDevice
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToNull
  nameWithType: SpeechRecognitionEngine.SetInputToNull
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveFile
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveStream
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadAllGrammars
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadGrammar
  nameWithType: SpeechRecognitionEngine.UnloadGrammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting
