### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.RecognitionResult
  id: RecognitionResult
  children:
  - System.Speech.Recognition.RecognitionResult.Alternates
  - System.Speech.Recognition.RecognitionResult.Audio
  - System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  - System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  langs:
  - csharp
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
  type: Class
  summary: "인스턴스에서 인식 된 입력에 대 한 자세한 정보가 포함 되어 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 또는 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref>합니다."
  remarks: "이 클래스에서 파생 <xref:System.Speech.Recognition.RecognizedPhrase>다음을 포함 한 음성 인식 하는 방법에 대 한 자세한 정보를 제공 하 고:- <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A>속성 참조는 <xref:System.Speech.Recognition.Grammar>인식기에서 음성을 식별 하는 데 사용 합니다.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> </xref:System.Speech.Recognition.RecognizedPhrase>      - <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A>속성 구에 대 한 정규화 된 텍스트를 포함 합니다.</xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> 텍스트 정규화에 대 한 자세한 내용은 <xref:System.Speech.Recognition.ReplacementText>.</xref:System.Speech.Recognition.ReplacementText> 을 참조 하십시오.      - <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A>결과에 포함 된 의미 체계 정보를 참조 하는 속성.</xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> 의미 체계 정보에는 키 이름 및 연결 된 의미 체계 데이터의 사전입니다.      - <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>속성의 컬렉션을 포함 <xref:System.Speech.Recognition.RecognizedPhrase>다른 후보 해석을 오디오 입력을 나타내는 개체입니다.</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> 참조 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>추가 정보에 대 한.</xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>      - <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A>속성의 정렬된 된 컬렉션에 포함 <xref:System.Speech.Recognition.RecognizedWordUnit>각각 나타내는 개체를 입력의 단어를 인식 합니다.</xref:System.Speech.Recognition.RecognizedWordUnit> </xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> 각 <xref:System.Speech.Recognition.RecognizedWordUnit>표시 형식, 어휘 형식 및 해당 단어에 대 한 발음 정보를 포함 합니다.</xref:System.Speech.Recognition.RecognizedWordUnit>       특정 멤버는 <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, 및 <xref:System.Speech.Recognition.Grammar>클래스는 RecognitionResult를 생성할 수 있습니다.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognizer> </xref:System.Speech.Recognition.SpeechRecognitionEngine> 자세한 내용은 다음 메서드 및 이벤트를 참조 하십시오.      -   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class:          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>      -   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognizer> class:          -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>          -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>      -   The <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event of the <xref:System.Speech.Recognition.Grammar> class.</xref:System.Speech.Recognition.Grammar></xref:System.Speech.Recognition.Grammar.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected></xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized></xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A></xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A></xref:System.Speech.Recognition.SpeechRecognizer></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized></xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine>       인식 이벤트에 대 한 자세한 내용은 참조 [음성 인식 이벤트를 사용 하 여](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)합니다."
  example:
  - "The following example shows a handler for the `SpeechRecognized` event of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> or <xref:System.Speech.Recognition.SpeechRecognizer> object, and some of the information about the associated RecognitionResult.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n  Console.WriteLine(\"Grammar({0}), {1}: {2}\",  \n    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: >-
      [System.Diagnostics.DebuggerDisplay("{DebuggerDisplayString ()}")]

      public sealed class RecognitionResult : System.Speech.Recognition.RecognizedPhrase, System.Runtime.Serialization.ISerializable
  inheritance:
  - System.Object
  - System.Speech.Recognition.RecognizedPhrase
  implements:
  - System.Runtime.Serialization.ISerializable
  inheritedMembers:
  - System.Speech.Recognition.RecognizedPhrase.Confidence
  - System.Speech.Recognition.RecognizedPhrase.ConstructSmlFromSemantics
  - System.Speech.Recognition.RecognizedPhrase.Grammar
  - System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId
  - System.Speech.Recognition.RecognizedPhrase.Homophones
  - System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits
  - System.Speech.Recognition.RecognizedPhrase.Semantics
  - System.Speech.Recognition.RecognizedPhrase.Text
  - System.Speech.Recognition.RecognizedPhrase.Words
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.Alternates
  id: Alternates
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: Alternates
  nameWithType: RecognitionResult.Alternates
  fullName: System.Speech.Recognition.RecognitionResult.Alternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기에 대 한 입력에 대 한 가능한 일치 항목의 컬렉션을 가져옵니다."
  remarks: "인식 대체 항목의 값에 따라 상대적으로 정렬 자신의 <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>속성.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> 특정된 구문의 신뢰성 값 구 입력과 일치 확률을 나타냅니다. 가장 높은 신뢰도 값을 가진 입력을 가장 일치 하는 구를 이라는 합니다.       각 <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>개별적으로 및 다른 대체 신뢰도 값을 참조 하지 않고 값을 평가 해야 합니다.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> 속성 하는 <xref:System.Speech.Recognition.RecognitionResult>에서 상속 <xref:System.Speech.Recognition.RecognizedPhrase>와 신뢰성 점수가 가장 높은 구를 검색 하는 방법에 대 한 자세한 정보를 제공 합니다.</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult>       자동화 된 오류 수정은 대체 항목 컬렉션에 대 한 사용 됩니다. 예를 들어 디렉터리 대화 상자를 디자인할 때 응용 프로그램 묻는 메시지가 응용 프로그램에서와 같이 인식 이벤트에서 올바른 정보를 보유 하는 경우 &quot;가 있습니다 &quot;Anna&quot;?&quot;를 확인 하려면 사용자가 &quot;no&quot; 인 경우 응용 프로그램에서 충분히 높은 수 있었던 모든 대체 항목에 대 한 사용자를 쿼리할 수 <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>점수.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>       음성 인식 및 인식 대체 항목을 사용 하는 방법에 대 한 자세한 내용은 참조 [음성 인식](http://msdn.microsoft.com/en-us/6a7dc524-07fc-4862-8d48-8c10dc64b919) 및 [음성 인식 이벤트를 사용 하 여](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)합니다."
  example:
  - "The following example shows a handler for the `SpeechRecognized` event and some of the information about the associated <xref:System.Speech.Recognition.RecognitionResult>.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n  Console.WriteLine(\"Grammar({0}), {1}: {2}\",  \n    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase> Alternates { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizedPhrase}
      description: "인식 대체 항목의 읽기 전용 컬렉션입니다."
  overload: System.Speech.Recognition.RecognitionResult.Alternates*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.Audio
  id: Audio
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: Audio
  nameWithType: RecognitionResult.Audio
  fullName: System.Speech.Recognition.RecognitionResult.Audio
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "인식 결과와 관련 된 오디오를 가져옵니다."
  remarks: "인식 결과 있는 단어의 특정 범위와 연결 된 오디오의 한 섹션을 사용은 <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A>메서드.</xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A>"
  example:
  - "The following example shows a handler for the **SpeechRecognized** event and some of the information about the associated <xref:System.Speech.Recognition.RecognitionResult>.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n      Console.WriteLine(\"Audio for result:\");  \n      Console.WriteLine(\"  Start time: \"+ e.Result.Audio.StartTime);  \n      Console.WriteLine(\"  Duration: \" + e.Result.Audio.Duration);  \n      Console.WriteLine(\"  Format: \" + e.Result.Audio.Format.EncodingFormat);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizedAudio Audio { get; }
    return:
      type: System.Speech.Recognition.RecognizedAudio
      description: "인식 결과와 관련 된 오디오 또는 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> 인식기에 대 한 호출에서 결과 생성 하는 경우는 <xref uid=&quot;langword_csharp_EmulateRecognize&quot; name=&quot;EmulateRecognize&quot; href=&quot;&quot;> </xref> 또는 <xref uid=&quot;langword_csharp_EmulateRecognizeAsync&quot; name=&quot;EmulateRecognizeAsync&quot; href=&quot;&quot;> </xref> 의 메서드는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 또는 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> 인스턴스."
  overload: System.Speech.Recognition.RecognitionResult.Audio*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  id: GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  nameWithType: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  fullName: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "인식 결과 있는 단어의 특정 범위와 연결 된 오디오의 섹션을 가져옵니다."
  remarks: "인식 결과와 관련 된 전체 오디오를 가져오려면는 <xref:System.Speech.Recognition.RecognitionResult.Audio%2A>속성.</xref:System.Speech.Recognition.RecognitionResult.Audio%2A>"
  example:
  - "The following example creates a grammar to accept name input and attaches to it a handler for the `SpeechRecognized` event. The grammar uses a wildcard for the name element of the phrase. The event handler uses the audio from the wildcard to create and play a greeting prompt.  \n  \n```c#  \n  \nprivate Grammar CreateNameInputGrammar()  \n{  \n  GrammarBuilder wildcardBuilder = new GrammarBuilder();  \n  wildcardBuilder.AppendWildcard();  \n  SemanticResultKey nameKey =  \n    new SemanticResultKey(\"Name\", wildcardBuilder);  \n  \n  GrammarBuilder nameBuilder =  \n    new GrammarBuilder(\"My name is\");  \n  nameBuilder.Append(nameKey);  \n  \n  Grammar nameGrammar = new Grammar(nameBuilder);  \n  nameGrammar.Name = \"Name input\";  \n  \n  nameGrammar.SpeechRecognized +=  \n    new EventHandler<SpeechRecognizedEventArgs>(  \n      NameInputHandler);  \n  \n  return nameGrammar;  \n}  \n  \n// Handle the SpeechRecognized event for the name grammar.  \nprivate void NameInputHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  RecognitionResult result = e.Result;  \n  SemanticValue semantics = e.Result.Semantics;  \n  \n  if (semantics.ContainsKey(\"Name\"))  \n  {  \n    RecognizedAudio nameAudio =  \n      result.GetAudioForWordRange(  \n        result.Words[3], result.Words[result.Words.Count - 1]);  \n  \n    // Save the audio. Create a directory and file as necessary.  \n    FileInfo fi = new FileInfo(@\"C:\\temp\\temp.wav\");  \n    if (!fi.Directory.Exists)  \n    {  \n      fi.Directory.Create();  \n    }  \n    FileStream stream = new FileStream(fi.FullName, FileMode.Create);  \n    nameAudio.WriteToWaveStream(stream);  \n    stream.Close();  \n  \n    // Greet the person using the saved audio.  \n    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  \n    PromptBuilder builder = new PromptBuilder();  \n    builder.AppendText(\"Hello\");  \n    builder.AppendAudio(fi.FullName);  \n    synthesizer.Speak(builder);  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizedAudio GetAudioForWordRange (System.Speech.Recognition.RecognizedWordUnit firstWord, System.Speech.Recognition.RecognizedWordUnit lastWord);
    parameters:
    - id: firstWord
      type: System.Speech.Recognition.RecognizedWordUnit
      description: "범위에서 첫 번째 단어입니다."
    - id: lastWord
      type: System.Speech.Recognition.RecognizedWordUnit
      description: "범위에서 마지막 단어입니다."
    return:
      type: System.Speech.Recognition.RecognizedAudio
      description: "Word 범위에 연결 된 오디오의 섹션입니다."
  overload: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange*
  exceptions:
  - type: System.NullReferenceException
    commentId: T:System.NullReferenceException
    description: "인식기는 결과에 대 한 호출에서 생성 된 <xref uid=&quot;langword_csharp_EmulateRecognize&quot; name=&quot;EmulateRecognize&quot; href=&quot;&quot;> </xref> 또는 <xref uid=&quot;langword_csharp_EmulateRecognizeAsync&quot; name=&quot;EmulateRecognizeAsync&quot; href=&quot;&quot;> </xref> 의 메서드는 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> 또는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 개체입니다."
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  id: System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  isEii: true
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  fullName: System.Speech.Recognition.RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "정보를 표시 한 <xref href=&quot;System.Runtime.Serialization.SerializationInfo&quot;> </xref> 대상 개체를 직렬화 하는 데 필요한 데이터를 사용 하 여 인스턴스."
  remarks: "이 멤버는 명시적 인터페이스 멤버 구현 이며 사용할 수 있습니다 경우에만 <xref:System.Speech.Recognition.RecognitionResult>인스턴스로 캐스팅 되는 <xref:System.Runtime.Serialization.ISerializable>인터페이스.</xref:System.Runtime.Serialization.ISerializable> </xref:System.Speech.Recognition.RecognitionResult>"
  syntax:
    content: void ISerializable.GetObjectData (System.Runtime.Serialization.SerializationInfo info, System.Runtime.Serialization.StreamingContext context);
    parameters:
    - id: info
      type: System.Runtime.Serialization.SerializationInfo
      description: "데이터로 채울 개체입니다."
    - id: context
      type: System.Runtime.Serialization.StreamingContext
      description: "serialization에 대 한 대상입니다."
  overload: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData*
  exceptions: []
  platform:
  - net462
references:
- uid: System.Speech.Recognition.RecognizedPhrase
  isExternal: false
  name: System.Speech.Recognition.RecognizedPhrase
- uid: System.NullReferenceException
  isExternal: true
  name: System.NullReferenceException
- uid: System.Speech.Recognition.RecognitionResult.Alternates
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Alternates
  nameWithType: RecognitionResult.Alternates
  fullName: System.Speech.Recognition.RecognitionResult.Alternates
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizedPhrase}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<RecognizedPhrase>
  nameWithType: ReadOnlyCollection<RecognizedPhrase>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizedPhrase
    name: RecognizedPhrase
    nameWithType: RecognizedPhrase
    fullName: RecognizedPhrase
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.RecognitionResult.Audio
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Audio
  nameWithType: RecognitionResult.Audio
  fullName: System.Speech.Recognition.RecognitionResult.Audio
- uid: System.Speech.Recognition.RecognizedAudio
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedAudio
  nameWithType: RecognizedAudio
  fullName: System.Speech.Recognition.RecognizedAudio
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  nameWithType: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  fullName: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
- uid: System.Speech.Recognition.RecognizedWordUnit
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  fullName: System.Speech.Recognition.RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
- uid: System.Runtime.Serialization.SerializationInfo
  parent: System.Runtime.Serialization
  isExternal: false
  name: SerializationInfo
  nameWithType: SerializationInfo
  fullName: System.Runtime.Serialization.SerializationInfo
- uid: System.Runtime.Serialization.StreamingContext
  parent: System.Runtime.Serialization
  isExternal: true
  name: StreamingContext
  nameWithType: StreamingContext
  fullName: System.Runtime.Serialization.StreamingContext
- uid: System.Speech.Recognition.RecognitionResult.Alternates*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Alternates
  nameWithType: RecognitionResult.Alternates
- uid: System.Speech.Recognition.RecognitionResult.Audio*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Audio
  nameWithType: RecognitionResult.Audio
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: GetAudioForWordRange
  nameWithType: RecognitionResult.GetAudioForWordRange
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: System.Runtime.Serialization.ISerializable.GetObjectData
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData
