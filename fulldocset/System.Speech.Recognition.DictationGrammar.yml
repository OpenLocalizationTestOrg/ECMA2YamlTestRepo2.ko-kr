### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.DictationGrammar
  id: DictationGrammar
  children:
  - System.Speech.Recognition.DictationGrammar.#ctor
  - System.Speech.Recognition.DictationGrammar.#ctor(System.String)
  - System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)
  langs:
  - csharp
  name: DictationGrammar
  nameWithType: DictationGrammar
  fullName: System.Speech.Recognition.DictationGrammar
  type: Class
  summary: "자유 텍스트 받아쓰기에 사용 되는 음성 인식 문법을 나타냅니다."
  remarks: "이 클래스는 응용 프로그램 텍스트에 대 한 음성된 사용자 입력을 처리할 수 있는 미리 정의 된 언어 모델을 제공 합니다. 이 클래스는 기본 및 사용자 지정 DictationGrammar 개체를 지원합니다. 선택 받아쓰기 문법에 대 한 정보를 참조 하십시오.는 <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29>생성자.</xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29>       기본적으로 DictationGrammar 언어 모델은 무료 컨텍스트입니다. 특정 단어의 사용 하거나 순서를 식별 하 여 오디오 입력 해석 단어 만들지 않습니다. 받아쓰기 문법에 컨텍스트를 추가 하려면 사용 된 <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A>메서드.</xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A>      > [!NOTE] > DictationGrammar 개체는 지원 하지는 <xref:System.Speech.Recognition.Grammar.Priority%2A>속성.</xref:System.Speech.Recognition.Grammar.Priority%2A> DictationGrammar throw 한 <xref:System.NotSupportedException>경우 <xref:System.Speech.Recognition.Grammar.Priority%2A>설정 됩니다.</xref:System.Speech.Recognition.Grammar.Priority%2A> </xref:System.NotSupportedException>"
  example:
  - "The following example creates three dictation grammars, adds them to a new <xref:System.Speech.Recognition.SpeechRecognitionEngine> object, and returns the new object. The first grammar is the default dictation grammar. The second grammar is the spelling dictation grammar. The third grammar is the default dictation grammar that includes a context phrase. The <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> method is used to associate the context phrase with the dictation grammar after it is loaded to the <xref:System.Speech.Recognition.SpeechRecognitionEngine> object.  \n  \n```c#  \n  \nprivate SpeechRecognitionEngine LoadDictationGrammars()  \n{  \n  \n  // Create a default dictation grammar.  \n  DictationGrammar defaultDictationGrammar = new DictationGrammar();  \n  defaultDictationGrammar.Name = \"default dictation\";  \n  defaultDictationGrammar.Enabled = true;  \n  \n  // Create the spelling dictation grammar.  \n  DictationGrammar spellingDictationGrammar =  \n    new DictationGrammar(\"grammar:dictation#spelling\");  \n  spellingDictationGrammar.Name = \"spelling dictation\";  \n  spellingDictationGrammar.Enabled = true;  \n  \n  // Create the question dictation grammar.  \n  DictationGrammar customDictationGrammar =  \n    new DictationGrammar(\"grammar:dictation\");  \n  customDictationGrammar.Name = \"question dictation\";  \n  customDictationGrammar.Enabled = true;  \n  \n  // Create a SpeechRecognitionEngine object and add the grammars to it.  \n  SpeechRecognitionEngine recoEngine = new SpeechRecognitionEngine();  \n  recoEngine.LoadGrammar(defaultDictationGrammar);  \n  recoEngine.LoadGrammar(spellingDictationGrammar);  \n  recoEngine.LoadGrammar(customDictationGrammar);  \n  \n  // Add a context to customDictationGrammar.  \n  customDictationGrammar.SetDictationContext(\"How do you\", null);  \n  \n  return recoEngine;  \n}  \n  \n```"
  syntax:
    content: 'public class DictationGrammar : System.Speech.Recognition.Grammar'
  inheritance:
  - System.Object
  - System.Speech.Recognition.Grammar
  implements: []
  inheritedMembers:
  - System.Speech.Recognition.Grammar.Enabled
  - System.Speech.Recognition.Grammar.IsStg
  - System.Speech.Recognition.Grammar.Loaded
  - System.Speech.Recognition.Grammar.LoadLocalizedGrammarFromType(System.Type,System.Object[])
  - System.Speech.Recognition.Grammar.Name
  - System.Speech.Recognition.Grammar.Priority
  - System.Speech.Recognition.Grammar.ResourceName
  - System.Speech.Recognition.Grammar.RuleName
  - System.Speech.Recognition.Grammar.SpeechRecognized
  - System.Speech.Recognition.Grammar.StgInit(System.Object[])
  - System.Speech.Recognition.Grammar.Weight
  platform:
  - net462
- uid: System.Speech.Recognition.DictationGrammar.#ctor
  id: '#ctor'
  parent: System.Speech.Recognition.DictationGrammar
  langs:
  - csharp
  name: DictationGrammar()
  nameWithType: DictationGrammar.DictationGrammar()
  fullName: System.Speech.Recognition.DictationGrammar.DictationGrammar()
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "새 인스턴스를 초기화는 <xref href=&quot;System.Speech.Recognition.DictationGrammar&quot;> </xref> Windows 데스크톱 음성 기술에서 제공 하는 기본 받아쓰기 문법에 대 한 클래스입니다."
  remarks: "기본 받아쓰기 문법 문장 부호를 포함 하 여 표준 받아쓰기 사례를 에뮬레이션 합니다. 단어의 맞춤법을 지원 하지는 않습니다."
  syntax:
    content: public DictationGrammar ();
    parameters: []
  overload: System.Speech.Recognition.DictationGrammar.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.DictationGrammar.#ctor(System.String)
  id: '#ctor(System.String)'
  parent: System.Speech.Recognition.DictationGrammar
  langs:
  - csharp
  name: DictationGrammar(String)
  nameWithType: DictationGrammar.DictationGrammar(String)
  fullName: System.Speech.Recognition.DictationGrammar.DictationGrammar(String)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "새 인스턴스를 초기화는 <xref href=&quot;System.Speech.Recognition.DictationGrammar&quot;> </xref> 특정 받아쓰기 문법을 사용 하 여 클래스입니다."
  remarks: "음성 플랫폼 특별 한 URI 구문을 사용 하 여 사용자 지정 받아쓰기 문법을 정의 합니다. 값 `grammar:dictation` 기본 받아쓰기 문법을 나타냅니다. 값 `grammar:dictation#spelling` 맞춤법 받아쓰기 문법을 나타냅니다."
  syntax:
    content: public DictationGrammar (string topic);
    parameters:
    - id: topic
      type: System.String
      description: "XML 호환 유니버설 리소스 식별자 (URI) 하거나 받아쓰기 문법을 지정 하는 `grammar:dictation` 또는 `grammar:dictation#spelling`합니다."
  overload: System.Speech.Recognition.DictationGrammar.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)
  id: SetDictationContext(System.String,System.String)
  parent: System.Speech.Recognition.DictationGrammar
  langs:
  - csharp
  name: SetDictationContext(String,String)
  nameWithType: DictationGrammar.SetDictationContext(String,String)
  fullName: System.Speech.Recognition.DictationGrammar.SetDictationContext(String,String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "컨텍스트를 하 여 로드 된 받아쓰기 문법에 추가 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> 또는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> 개체입니다."
  remarks: "기본적으로 받아쓰기 문법 미치지 않으며 특정 단어의 사용 또는 단어 순서를 식별 하 여 오디오 입력을 해석 합니다. 인식 엔진에 사용 하 여 컨텍스트를 받아쓰기 문법에 추가 되는 `precedingText` 및 `subsequentText` 음성 받아쓰기로 해석 하는 시기를 식별 하 합니다.      > [!NOTE] > 받아쓰기 문법을 로드 해야는 <xref:System.Speech.Recognition.SpeechRecognizer>또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine>개체 컨텍스트를 추가 하려면 SetDictationContext을 사용할 수 있습니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.SpeechRecognizer>       다음 표에서 인식 엔진 받아쓰기 문법을 사용 하는 시기를 결정 하는 두 개의 매개 변수를 사용 하는 방법을 설명 합니다.      | `precedingText`|`subsequentText`| 설명 |   |---------------------|----------------------|-----------------|   |not `null`|not `null`| 인식 엔진 용어를 사용 하 여 가능한 후보 구 묶습니다. |   | `null`|not `null`| 인식 엔진 사용 하 여는 `subsequentText` 받아쓰기 끝나기를. |   |not `null`|`null`| 인식 엔진 사용 하 여는 `precedingText` 받아쓰기를 시작 합니다. |   | `null`|`null`| 인식 엔진 받아쓰기 문법을 사용 하 여 때 컨텍스트를 사용 하지 않습니다. |"
  syntax:
    content: public void SetDictationContext (string precedingText, string subsequentText);
    parameters:
    - id: precedingText
      type: System.String
      description: "받아쓰기 컨텍스트의 시작을 나타내는 텍스트입니다."
    - id: subsequentText
      type: System.String
      description: "받아쓰기 컨텍스트의 끝을 나타내는 텍스트입니다."
  overload: System.Speech.Recognition.DictationGrammar.SetDictationContext*
  exceptions: []
  platform:
  - net462
references:
- uid: System.Speech.Recognition.Grammar
  isExternal: false
  name: System.Speech.Recognition.Grammar
- uid: System.Speech.Recognition.DictationGrammar.#ctor
  parent: System.Speech.Recognition.DictationGrammar
  isExternal: false
  name: DictationGrammar()
  nameWithType: DictationGrammar.DictationGrammar()
  fullName: System.Speech.Recognition.DictationGrammar.DictationGrammar()
- uid: System.Speech.Recognition.DictationGrammar.#ctor(System.String)
  parent: System.Speech.Recognition.DictationGrammar
  isExternal: false
  name: DictationGrammar(String)
  nameWithType: DictationGrammar.DictationGrammar(String)
  fullName: System.Speech.Recognition.DictationGrammar.DictationGrammar(String)
- uid: System.String
  parent: System
  isExternal: true
  name: String
  nameWithType: String
  fullName: System.String
- uid: System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)
  parent: System.Speech.Recognition.DictationGrammar
  isExternal: false
  name: SetDictationContext(String,String)
  nameWithType: DictationGrammar.SetDictationContext(String,String)
  fullName: System.Speech.Recognition.DictationGrammar.SetDictationContext(String,String)
- uid: System.Speech.Recognition.DictationGrammar.#ctor*
  parent: System.Speech.Recognition.DictationGrammar
  isExternal: false
  name: DictationGrammar
  nameWithType: DictationGrammar.DictationGrammar
- uid: System.Speech.Recognition.DictationGrammar.SetDictationContext*
  parent: System.Speech.Recognition.DictationGrammar
  isExternal: false
  name: SetDictationContext
  nameWithType: DictationGrammar.SetDictationContext
