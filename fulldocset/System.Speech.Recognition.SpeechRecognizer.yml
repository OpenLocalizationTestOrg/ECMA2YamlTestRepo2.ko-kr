### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.SpeechRecognizer
  id: SpeechRecognizer
  children:
  - System.Speech.Recognition.SpeechRecognizer.#ctor
  - System.Speech.Recognition.SpeechRecognizer.AudioFormat
  - System.Speech.Recognition.SpeechRecognizer.AudioLevel
  - System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  - System.Speech.Recognition.SpeechRecognizer.AudioPosition
  - System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  - System.Speech.Recognition.SpeechRecognizer.AudioState
  - System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  - System.Speech.Recognition.SpeechRecognizer.Dispose
  - System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  - System.Speech.Recognition.SpeechRecognizer.Enabled
  - System.Speech.Recognition.SpeechRecognizer.Grammars
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  - System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  - System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  - System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  - System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  - System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  - System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  - System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  - System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  - System.Speech.Recognition.SpeechRecognizer.State
  - System.Speech.Recognition.SpeechRecognizer.StateChanged
  - System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  - System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  langs:
  - csharp
  name: SpeechRecognizer
  nameWithType: SpeechRecognizer
  fullName: System.Speech.Recognition.SpeechRecognizer
  type: Class
  summary: "Windows 바탕 화면에서 사용할 수 있는 공유 음성 인식 서비스에 대 한 액세스를 제공합니다."
  remarks: "응용 프로그램 공유 인식기를 사용 하 여 Windows 음성 인식을 액세스할 수 있습니다. 음성 Windows 사용자 환경에 추가할 SpeechRecognizer 개체를 사용 합니다.       이 클래스는 음성 인식 프로세스의 다양 한 측면에 대 한 제어를 제공:-음성 인식 문법 관리을 사용 하려면는 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>.</xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> </xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A> </xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>      -현재 음성에 대 한 정보는 인식 작업을 가져오려면에 가입 된 SpeechRecognizer <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>이벤트.</xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>      -사용을 확인 하거나 인식기에서 반환 하는 대체 결과의 수를 수정 하려면는 <xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A>속성.</xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> 인식기에서 인식 결과 반환 합니다.는 <xref:System.Speech.Recognition.RecognitionResult>개체입니다.</xref:System.Speech.Recognition.RecognitionResult>      -액세스 공유 인식기에서의 상태를 모니터링 하거나를 사용 하 여는 <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.State%2A>속성 및 <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>이벤트.</xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> </xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged> </xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred> </xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated> </xref:System.Speech.Recognition.SpeechRecognizer.State%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>      -인식기에 변경 내용을 동기화를 사용 하 여는 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 공유 인식기에서 둘 이상의 스레드를 사용 하 여 작업을 수행할 수 있습니다.      -공유 인식기에 대 한 입력을 에뮬레이트 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>및 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>       Windows 음성 인식을의 구성을 사용 하 여 관리 되는 **음성 속성** 대화 상자에는 **제어판**합니다. 이 인터페이스는 기본 데스크톱 음성 인식 엔진 및 언어, 오디오 입력된 장치 및 음성 인식의 절전 모드 동작을 선택 하려면 사용 됩니다. (예를 들어, 음성 인식을 사용 불가능 하거나 경우 입력된 언어가 변경 된) 응용 프로그램이 실행 되는 동안 Windows 음성 인식의 구성을 변경 하는 경우, 모든 SpeechRecognizer 개체에 변경 내용이 적용 됩니다.       <xref:System.Speech.Recognition.SpeechRecognitionEngine>클래스</xref:System.Speech.Recognition.SpeechRecognitionEngine> 를 사용 하 여 음성 인식 Windows와 독립적인 프로세스에서 음성 인식기를 만들려면      > [!NOTE] > 항상 호출 <xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A>음성 인식기에 대 한 마지막 참조를 해제 하기 전에.</xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A> 가비지 수집기 인식기 개체를 호출할 때까지 사용 중인 리소스를 해제 되지 것입니다 그렇지 않으면 `Finalize` 메서드."
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.  If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.   \n        // This matches the grammar and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.  \n        // This does not match the grammar or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the SpeechRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: 'public class SpeechRecognizer : IDisposable'
  inheritance:
  - System.Object
  implements:
  - System.IDisposable
  inheritedMembers: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor
  id: '#ctor'
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognizer()
  nameWithType: SpeechRecognizer.SpeechRecognizer()
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognizer()
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "새 인스턴스를 초기화는 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> 클래스입니다."
  remarks: "각 <xref:System.Speech.Recognition.SpeechRecognizer>개체 음성 인식 문법의 별도 집합을 유지 관리 합니다.</xref:System.Speech.Recognition.SpeechRecognizer>"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.   \n        // This matches the grammar and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.  \n        // This does not match the grammar or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the SpeechRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public SpeechRecognizer ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  id: AudioFormat
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기에서 수신 되는 오디오의 형식을 가져옵니다."
  syntax:
    content: public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }
    return:
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "음성 인식기에 오디오 입력된 형식 또는 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> 인식기에 대 한 입력을 구성 하지 않은 경우."
  overload: System.Speech.Recognition.SpeechRecognizer.AudioFormat*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  id: AudioLevel
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기에서 수신 되는 오디오의 수준을 가져옵니다."
  syntax:
    content: public int AudioLevel { get; }
    return:
      type: System.Int32
      description: "0에서 100 사이의 음성 인식기에서 입력의 오디오 수준입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.AudioLevel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  id: AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioLevelUpdated
  nameWithType: SpeechRecognizer.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "공유 인식기에 오디오 입력 값의 수준을 보고 하면 발생 합니다."
  remarks: "인식기에서 초당 여러 번이이 이벤트를 발생 시킵니다. 응용 프로그램이 실행 중인 컴퓨터에는 이벤트가 발생 하는 빈도 따라 다릅니다.       오디오 수준에서 이벤트의 시간을 가져오려면 <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>.</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs> 연결된의 속성</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> 을 사용 하 여 오디오 현재 수준의 인식기에 대 한 입력을 사용 하면 인식기 <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>속성.</xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>       에 대 한 대리자를 만들 때는 `AudioLevelUpdated` 이벤트를 처리 하는 메서드를 식별 이벤트를 실행 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example adds a handler for the `AudioLevelUpdated` event to a <xref:System.Speech.Recognition.SpeechRecognizer> object. The handler outputs the new audio level to the console.  \n  \n```c#  \nprivate SpeechRecognizer recognizer;  \n  \n// Initialize the SpeechRecognizer object.   \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognizer();  \n  \n  // Add an event handler for the AudioLevelUpdated event.  \n  recognizer.AudioLevelUpdated +=   \n    new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  \n  \n  // Add other initialization code here.  \n  \n}  \n  \n// Write the audio level to the console when the AudioLevelUpdated event is raised.  \nvoid recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  \n{  \n  Console.WriteLine(\"The audio level is now: {0}.\", e.AudioLevel);  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs> AudioLevelUpdated;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  id: AudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기에 대 한 입력을 제공 하는 장치에 의해 생성 되 고 오디오 스트림 내의 현재 위치를 가져옵니다."
  remarks: "데스크톱 음성 인식 실행 되는 동안 공유 인식기에서 입력을 받습니다.       `AudioPosition` 속성 입력된 장치 위치에 생성 된 오디오 스트림 참조 합니다. 반면,는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>속성 오디오 입력을 처리에서 인식기에서 위치를 참조 합니다.</xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> 이 위치는 다를 수 있습니다.  인식기에서 받는 경우 하지는 자신이 입력 하 아직 인식 결과 다음 값을 생성 합니다. 예를 들어는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>AudioPosition 속성의 값 보다 작아야 합니다.</xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>"
  example:
  - "In the following example, the shared speech recognizer uses a dictation grammar to match speech input. A handler for the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> event writes to the console the AudioPosition, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, and  <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> when the speech recognizer detects speech at its input.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Add handlers for events.  \n      recognizer.LoadGrammarCompleted +=   \n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n      recognizer.SpeechRecognized +=   \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n      recognizer.StateChanged +=   \n        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n      recognizer.SpeechDetected +=   \n        new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n  \n      // Create a dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load the grammar object to the recognizer.  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Gather information about detected speech and write it to the console.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Speech detected:\");  \n      Console.WriteLine(\"  Audio level: \" + recognizer.AudioLevel);  \n      Console.WriteLine(\"  Audio position: \" + recognizer.AudioPosition);  \n      Console.WriteLine(\"  Recognizer audio position: \" + recognizer.RecognizerAudioPosition);  \n    }  \n  \n    // Write the text of the recognition result to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {   \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Write the name of the loaded grammar to the console.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan AudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "음성 인식기의 오디오 입력된 스트림을 통해 수신한 입력 내의 현재 위치입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.AudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  id: AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognizer.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "인식기에 오디오 신호의 문제가 발생 하는 경우 발생 합니다."
  remarks: "어떤 문제가 발생 한을 가져오려면 <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>.</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> 연결된의 속성</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> 을 사용 하 여       에 대 한 대리자를 만들 때는 `AudioSignalProblemOccurred` 이벤트를 처리 하는 메서드를 식별 이벤트를 실행 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example defines an event handler that gathers information about an `AudioSignalProblemOccurred` event.  \n  \n```  \nprivate SpeechRecognizer recognizer;  \n  \n// Initialize the speech recognition engine.  \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognizer();  \n  \n  // Add a handler for the AudioSignalProblemOccurred event.  \n  recognizer.AudioSignalProblemOccurred +=   \n    new EventHandler<AudioSignalProblemOccurredEventArgs>(  \n      recognizer_AudioSignalProblemOccurred);  \n}  \n  \n// Gather information when the AudioSignalProblemOccurred event is raised.  \nvoid recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  \n{  \n  StringBuilder details = new StringBuilder();  \n  \n  details.AppendLine(\"Audio signal problem information:\");  \n  details.AppendFormat(  \n    \" Audio level:               {0}\" + Environment.NewLine +  \n    \" Audio position:            {1}\" + Environment.NewLine +  \n    \" Audio signal problem:      {2}\" + Environment.NewLine +  \n    \" Recognition engine audio position: {3}\" + Environment.NewLine,  \n    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  \n    e.recoEngineAudioPosition);  \n  \n  // Insert additional event handler code here.  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> AudioSignalProblemOccurred;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState
  id: AudioState
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioState
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식기에서 수신 되는 오디오의 상태를 가져옵니다."
  syntax:
    content: public System.Speech.Recognition.AudioState AudioState { get; }
    return:
      type: System.Speech.Recognition.AudioState
      description: "음성 인식기에 오디오 입력의 상태입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.AudioState*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  id: AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioStateChanged
  nameWithType: SpeechRecognizer.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "인식기에서 오디오의 상태 변경을 수신 될 때 발생 합니다."
  remarks: "이벤트의 시간에 오디오 상태를 가져오려면 <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> <xref:System.Speech.Recognition.AudioStateChangedEventArgs>.</xref:System.Speech.Recognition.AudioStateChangedEventArgs> 연결된의 속성</xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> 을 사용 하 여 사용 하 여 인식기에서 인식기에 대 한 입력의 오디오 현재 상태를 가져오려면 <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>속성.</xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> 오디오 상태에 대 한 자세한 내용은 참조는 <xref:System.Speech.Recognition.AudioState>열거형.</xref:System.Speech.Recognition.AudioState>       에 대 한 대리자를 만들 때는 `AudioStateChanged` 이벤트를 처리 하는 메서드를 식별 이벤트를 실행 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example uses a handler for the `AudioStateChanged` event to write the recognizer's new <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> to the console each time it changes using a member of the <xref:System.Speech.Recognition.AudioState> enumeration.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.StateChanged +=  \n          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n  \n    // Handle the AudioStateChanged event.  \n    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"The new audio state is: \" + e.AudioState);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine();  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Done.\");  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Put the recognizer into Listening mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        Console.WriteLine();  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs> AudioStateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose
  id: Dispose
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Dispose()
  nameWithType: SpeechRecognizer.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "삭제는 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> 개체입니다."
  syntax:
    content: public void Dispose ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  id: Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Dispose(Boolean)
  nameWithType: SpeechRecognizer.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose(Boolean)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "삭제는 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> 세션 중 사용 되는 개체 및 버전 리소스입니다."
  syntax:
    content: protected virtual void Dispose (bool disposing);
    parameters:
    - id: disposing
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>관리 되는 관리 되지 않는 리소스만 해제 하려면 <xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref> 만 관리 되지 않는 리소스를 해제 합니다."
  overload: System.Speech.Recognition.SpeechRecognizer.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  id: EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognizer.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "구의 오디오 대신 텍스트를 사용 하 여 동기 음성 인식 기능에 대 한 공유 음성 인식기에서 입력을 에뮬레이트합니다."
  remarks: "인식기 Vista 및 Windows 7과 함께 제공 되는 대/소문자를 무시 하 고 입력된 구를에 문법 규칙을 적용 하는 경우 너비를 문자. 이 유형의 비교에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형 값과 <xref:System.Globalization.CompareOptions>및 <xref:System.Globalization.CompareOptions>.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다."
  example:
  - "The following example loads a sample grammar to the shared recognizer and emulates input to the recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> always returns null.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        RecognitionResult result;  \n  \n        // This EmulateRecognize call matches the grammar and returns a  \n        // recognition result.  \n        result = recognizer.EmulateRecognize(\"testing testing\");  \n        OutputResult(result);  \n  \n        // This EmulateRecognize call does not match the grammar and   \n        // returns null.  \n        result = recognizer.EmulateRecognize(\"testing one two three\");  \n        OutputResult(result);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Output information about a recognition result to the console.  \n    private static void OutputResult(RecognitionResult result)  \n    {  \n      if (result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "인식 작업에 대 한 입력입니다."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "인식 작업에 대 한 인식 결과 또는 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>작업이 성공 하지 않습니다. Windows 음성 인식을 중인 경우는 **절전 모드** 상태입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "오디오 대신 텍스트를 사용 하 여 동기 음성 인식 기능에 대 한 공유 음성 인식기에 특정 단어의 입력을 에뮬레이트하고 인식기에서 단어 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다."
  remarks: "이 메서드가 만드는 <xref:System.Speech.Recognition.RecognitionResult>개체에 제공 된 정보를 사용 하 여는 `wordUnits` 매개 변수.</xref:System.Speech.Recognition.RecognitionResult>       인식기에서 사용 하 여는 `compareOptions` 때 문법 규칙 입력된 구문에 적용 합니다. 인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 <xref:System.Globalization.CompareOptions>또는 <xref:System.Globalization.CompareOptions>값이 있는.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 인식기에서 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다. 또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "인식 작업에 대 한 입력이 포함 된 배열 단어 단위입니다."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "인식 작업에 대 한 인식 결과 또는 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>작업이 성공 하지 않습니다. Windows 음성 인식을 중인 경우는 **절전 모드** 상태입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "오디오 대신 텍스트를 사용 하 여 동기 음성 인식 기능에 대 한 공유 음성 인식기에서에 대 한 입력 구의 에뮬레이트하고 인식기는 구를 검색 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다."
  remarks: "인식기에서 사용 하 여는 `compareOptions` 때 문법 규칙 입력된 구문에 적용 합니다. 인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 <xref:System.Globalization.CompareOptions>또는 <xref:System.Globalization.CompareOptions>값이 있는.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 인식기에서 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다. 또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "인식 작업에 대 한 입력된 구입니다."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "인식 작업에 대 한 인식 결과 또는 <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>작업이 성공 하지 않습니다. Windows 음성 인식을 중인 경우는 **절전 모드** 상태입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  id: EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "구의 오디오 대신 텍스트를 사용 하 여 비동기 음성 인식 기능에 대 한 공유 음성 인식기에서 입력을 에뮬레이트합니다."
  remarks: "인식기 Vista 및 Windows 7과 함께 제공 되는 대/소문자를 무시 하 고 입력된 구를에 문법 규칙을 적용 하는 경우 너비를 문자. 이 유형의 비교에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형 값과 <xref:System.Globalization.CompareOptions>및 <xref:System.Globalization.CompareOptions>.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다."
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar   \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.   \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "인식 작업에 대 한 입력입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "오디오 대신 텍스트를 사용 하 여 비동기 음성 인식 기능에 대 한 공유 음성 인식기에 특정 단어의 입력을 에뮬레이트하고 인식기에서 단어 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다."
  remarks: "이 메서드가 만드는 <xref:System.Speech.Recognition.RecognitionResult>개체에 제공 된 정보를 사용 하 여는 `wordUnits` 매개 변수.</xref:System.Speech.Recognition.RecognitionResult>       인식기에서 사용 하 여는 `compareOptions` 때 문법 규칙 입력된 구문에 적용 합니다. 인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 <xref:System.Globalization.CompareOptions>또는 <xref:System.Globalization.CompareOptions>값이 있는.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 인식기에서 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다. 또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "인식 작업에 대 한 입력이 포함 된 배열 단어 단위입니다."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "오디오 대신 텍스트를 사용 하 여 비동기 음성 인식 기능에 대 한 공유 음성 인식기에서에 대 한 입력 구의 에뮬레이트하고 인식기는 구를 검색 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다."
  remarks: "인식기에서 사용 하 여는 `compareOptions` 때 문법 규칙 입력된 구문에 적용 합니다. 인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 <xref:System.Globalization.CompareOptions>또는 <xref:System.Globalization.CompareOptions>값이 있는.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 인식기에서 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다. 또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions>열거형.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "인식 작업에 대 한 입력된 구입니다."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  id: EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognizer.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "공유 인식기 에뮬레이트된 입력에 대 한 비동기 인식 작업을 종료 하는 경우 발생 합니다."
  remarks: "각 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>메서드는 비동기 인식 작업을 시작 합니다.</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 인식기 발생은 `EmulateRecognizeCompleted` 비동기 작업을 완료 하는 경우 이벤트입니다.       비동기 인식 작업을 발생 시킬 수는 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>이벤트.</xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> EmulateRecognizeCompleted 이벤트는 마지막 이러한 이벤트 인식기에서 지정된 된 작업에 대 한를 발생 시킵니다.       에 대 한 대리자를 만들 때는 `EmulateRecognizeCompleted` 이벤트를 처리 하는 메서드를 식별 이벤트를 실행 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** mode, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=   \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar  \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> EmulateRecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled
  id: Enabled
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
  fullName: System.Speech.Recognition.SpeechRecognizer.Enabled
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "표시 하는 값을 가져오거나 설정 합니다. 여부이 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> 개체 음성 처리할 준비가 되었습니다."
  remarks: "이 속성의 변경 내용은 <xref:System.Speech.Recognition.SpeechRecognizer>클래스</xref:System.Speech.Recognition.SpeechRecognizer> 의 다른 인스턴스에 영향을 주지 않습니다.       기본적으로 Enabled 속성의 값은 `true` <xref:System.Speech.Recognition.SpeechRecognizer>안내 하십시오.</xref:System.Speech.Recognition.SpeechRecognizer> 새로 인스턴스화된 인스턴스에 대 한 인식기에서 해제 되어 있는 동안 인식기에서 음성 인식 문법 모두가 인식 작업에 사용할 수 있습니다. 인식기에 영향을 주지 인식기의 Enabled 속성을 설정 <xref:System.Speech.Recognition.SpeechRecognizer.State%2A>속성.</xref:System.Speech.Recognition.SpeechRecognizer.State%2A>"
  syntax:
    content: public bool Enabled { get; set; }
    return:
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>이 경우 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> 개체가 음성 인식을 수행 하 고, 그렇지 않으면, <xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref>합니다."
  overload: System.Speech.Recognition.SpeechRecognizer.Enabled*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars
  id: Grammars
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
  fullName: System.Speech.Recognition.SpeechRecognizer.Grammars
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "컬렉션을 가져옵니다는 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> 이 로드 되는 개체 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> 인스턴스."
  remarks: "이 속성 모든 음성 인식 문법 다른 응용 프로그램에 의해 로드 반환 하지 않습니다."
  example:
  - "The following example outputs information to the console for each speech recognition grammar loaded into the shared speech recognizer.  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        Grammar sampleGrammar = new Grammar(new GrammarBuilder(\"sample phrase\"));  \n        sampleGrammar.Name = \"Sample Grammar\";  \n        recognizer.LoadGrammar(sampleGrammar);  \n  \n        OutputGrammarList(recognizer);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void OutputGrammarList(SpeechRecognizer recognizer)  \n    {  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      if (grammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in grammars)  \n        {  \n          Console.WriteLine(\"  Grammar: {0}\",  \n            (g.Name != null) ? g.Name : \"<no name>\");  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n    }  \n}  \n  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar> Grammars { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
      description: "컬렉션은 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> 응용 프로그램이 공유 인식기에서의 현재 인스턴스를 로드 하는 개체입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.Grammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  id: LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식 문법을 로드합니다."
  remarks: "공유 인식기에서 음성 인식 문법이 이미 로드, 비동기적으로 로드 되 고, 또는 모든 인식기로 로드 하지 못한 경우 예외가 throw 됩니다. 응용 프로그램을 사용 해야 인식기에서 실행 중인 경우 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>를 로드, 언로드, 또는 사용 안 함 문법 하기 전에 음성 인식 엔진을 일시 중지 합니다.</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>       사용 하 여 음성 인식 문법을 비동기적으로 로드 하는 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar   \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }   \n  \n    // Handle the EmulateRecognizeCompleted event.   \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void LoadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "음성 인식 문법을 로드 합니다."
  overload: System.Speech.Recognition.SpeechRecognizer.LoadGrammar*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  id: LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "음성 인식 문법을 비동기적으로 로드 합니다."
  remarks: "이 비동기 작업을 완료 하는 인식기에서 발생 한 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted>이벤트.</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> 인식기에서 음성 인식 문법이 이미 로드, 비동기적으로 로드 되 고, 또는 모든 인식기로 로드 하지 못한 경우 예외가 throw 됩니다. 응용 프로그램을 사용 해야 인식기에서 실행 중인 경우 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>를 로드, 언로드, 또는 사용 안 함 문법 하기 전에 음성 인식 엔진을 일시 중지 합니다.</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>       음성 인식 문법에 동기적으로 로드 하려면 사용 하 여는 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>"
  syntax:
    content: public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "음성 인식 문법을 로드 합니다."
  overload: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  id: LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognizer.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "인식기에서 음성 인식 문법의 비동기 로딩을 마쳤을 때 발생 합니다."
  remarks: "인식기에서 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>메서드는 비동기 작업을 시작 합니다.</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> 인식기 발생은 `LoadGrammarCompleted` 이벤트는 작업을 완료 하는 경우. <xref:System.Speech.Recognition.Grammar>인식기에서 로드 하는 개체 <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>.</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs> 연결된의 속성</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> 을 사용</xref:System.Speech.Recognition.Grammar> 하려면 현재 가져오려는 <xref:System.Speech.Recognition.Grammar>인식기가 로드 하는 개체 인식기에서 사용 하 여 <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>속성.</xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> </xref:System.Speech.Recognition.Grammar>       에 대 한 대리자를 만들 때는 `LoadGrammarCompleted` 이벤트를 처리 하는 메서드를 식별 이벤트를 실행 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example asynchronously loads all the created grammars to the recognizer. Handlers for the recognizer's LoadGrammarCompleted and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events write to the console the name of the grammar that was used to perform the recognition and the text of the recognition result, respectively.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Add a handler for the StateChanged event.  \n        recognizer.StateChanged +=  \n          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n        // Create \"yesno\" grammar.  \n        Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yeah}\" });  \n        SemanticResultValue yesValue =  \n            new SemanticResultValue(yesChoices, (bool)true);  \n        Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"neah\" });  \n        SemanticResultValue noValue =  \n            new SemanticResultValue(noChoices, (bool)false);  \n        SemanticResultKey yesNoKey =  \n            new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n        Grammar yesnoGrammar = new Grammar(yesNoKey);  \n        yesnoGrammar.Name = \"yesNo\";  \n  \n        // Create \"done\" grammar.  \n        Grammar doneGrammar =  \n          new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n        doneGrammar.Name = \"Done\";  \n  \n        // Create dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation\";  \n  \n        // Load grammars to the recognizer.  \n        recognizer.LoadGrammarAsync(yesnoGrammar);  \n        recognizer.LoadGrammarAsync(doneGrammar);  \n        recognizer.LoadGrammarAsync(dictation);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.   \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n  \n        // Add exception handling code here.  \n      }  \n  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.   \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs> LoadGrammarCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  id: MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "각 인식 작업에 대 한 공유 인식기에서 반환 하는 대체 인식 결과의 최대 수를 가져오거나 설정 합니다."
  remarks: "<xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>속성은 <xref:System.Speech.Recognition.RecognitionResult>의 컬렉션을 포함 하는 클래스 <xref:System.Speech.Recognition.RecognizedPhrase>입력의 다른 후보 해석을 나타내는 개체입니다.</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       MaxAlternates의 기본값은 10입니다."
  syntax:
    content: public int MaxAlternates { get; set; }
    return:
      type: System.Int32
      description: "음성 인식기에서 각 인식 작업에 대 한 반환 하는 대체 결과의 최대 수입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.MaxAlternates*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  id: PauseRecognizerOnRecognition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
  fullName: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "응용 프로그램을 처리 하는 동안 공유 인식기에서 일시 인식 작업을 중지할지 여부를 나타내는 값을 가져오거나 설정 합니다.는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&quot;> </xref> 이벤트입니다."
  remarks: "이 속성을 설정 `true`경우 내에서 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>응용 프로그램 음성 인식 서비스는 추가 입력을 처리 하기 전에 로드 되거나 설정 된 음성 인식 문법을 변경 하거나 음성 인식 서비스의 상태를 변경 해야 하는 이벤트 처리기.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>      > [!NOTE] > 설정은 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>속성을 `true` 하면 각 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>Windows 음성 인식 서비스를 차단 하도록 모든 응용 프로그램에 대 한 이벤트 처리기.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>       사용 하 여 공유 인식기에 변경 내용을 응용 프로그램 상태를 동기화 하려면는 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>       PauseRecognizerOnRecognition 다음과 같은 경우 `true`를 실행 하는 동안는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>처리기 음성 인식 서비스 일시 중지 하 고 새 오디오 입력 버퍼에 도착 하는 대로.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> 한 번의 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>음성 인식 서비스 다시 시작 인식 및 입력된 버퍼에서 정보를 처리 하기 시작에 이벤트 처리기가 종료 됩니다.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>       음성 인식 서비스를 사용 하지 않도록 설정 하거나 설정 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>속성.</xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>"
  syntax:
    content: public bool PauseRecognizerOnRecognition { get; set; }
    return:
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>모든 응용 프로그램을 처리 하는 동안 입력을 처리 하기 위해 공유 인식기에서 대기 하는 경우는 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&quot;> </xref> 이벤트, 그렇지 않으면 <xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref>합니다."
  overload: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  id: RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "인식기에 오디오 입력을 처리 하는 현재 위치를 가져옵니다."
  remarks: "`RecognizerAudioPosition` 속성의 오디오 입력을 처리에서 인식기에서 위치를 참조 합니다. 반면,는 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>속성 참조의 생성 된 오디오 스트림 내의 위치를 입력된 장치.</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> 이 위치는 다를 수 있습니다. 예를 들어 인식기에서 받는 경우 하지는 자신이 입력 하면서도 RecognizerAudioPosition 속성의 값은의 값 보다 작은 인식 결과 생성 되는 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>속성.</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>"
  syntax:
    content: public TimeSpan RecognizerAudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "인식기에 오디오 입력을 처리 하는 위치입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  id: RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "공유 음성 인식기에 대 한 정보를 가져옵니다."
  remarks: "이 속성 사용 중인 Windows 음성 인식에서 음성 인식기에 대 한 정보를 반환합니다."
  example:
  - "The following example sends information about the shared recognizer to the console.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        Console.WriteLine(\"Recognizer information for the shared recognizer:\");  \n        Console.WriteLine(\"  Name: {0}\", recognizer.RecognizerInfo.Name);  \n        Console.WriteLine(\"  Culture: {0}\", recognizer.RecognizerInfo.Culture.ToString());  \n        Console.WriteLine(\"  Description: {0}\", recognizer.RecognizerInfo.Description);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }
    return:
      type: System.Speech.Recognition.RecognizerInfo
      description: "공유 음성 인식기에 대 한 정보입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  id: RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognizer.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "인식기에서 인식 및 기타 작업을 동기화 할 일시 중지 될 때 발생 합니다."
  remarks: "응용 프로그램 사용 해야 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>의 실행 중인 인스턴스 일시 중지 하려면 <xref:System.Speech.Recognition.SpeechRecognizer>수정 하기 전에 해당 <xref:System.Speech.Recognition.Grammar>개체.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognizer> </xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 예를 들어 동안는 <xref:System.Speech.Recognition.SpeechRecognizer>는 일시 중지 된 있습니다 수 로드, 언로드, 설정 및 해제 <xref:System.Speech.Recognition.Grammar>개체.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognizer> <xref:System.Speech.Recognition.SpeechRecognizer>수정을 수락할 준비가 되었을 때이 이벤트를 발생 시킵니다.</xref:System.Speech.Recognition.SpeechRecognizer>       RecognizerUpdateReached 이벤트에 대 한 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for RecognizerUpdateReached event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Create the first grammar - Farm.  \n      Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n      GrammarBuilder farm = new GrammarBuilder(animals);  \n      Grammar farmAnimals = new Grammar(farm);  \n      farmAnimals.Name = \"Farm\";  \n  \n      // Create the second grammar - Fruit.  \n      Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n      GrammarBuilder favorite = new GrammarBuilder(fruit);  \n      Grammar favoriteFruit = new Grammar(favorite);  \n      favoriteFruit.Name = \"Fruit\";  \n  \n      // Attach event handlers.  \n      recognizer.SpeechRecognized +=  \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n      recognizer.RecognizerUpdateReached +=  \n        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n      recognizer.StateChanged +=   \n        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n      // Load the Farm grammar.  \n      recognizer.LoadGrammar(farmAnimals);  \n      Console.WriteLine(\"Grammar Farm is loaded\");  \n  \n      // Pause to recognize farm animals.  \n      Thread.Sleep(7000);  \n      Console.WriteLine();  \n  \n      // Request an update and load the Fruit grammar.  \n      recognizer.RequestRecognizerUpdate();  \n      recognizer.LoadGrammarAsync(favoriteFruit);  \n      Thread.Sleep(5000);  \n  \n      // Request an update and unload the Farm grammar.  \n      recognizer.RequestRecognizerUpdate();  \n      recognizer.UnloadGrammar(farmAnimals);  \n      Thread.Sleep(5000);  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  Grammar {0} is loaded and is {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs> RecognizerUpdateReached;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  id: RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "공유 인식기에서 일시 중지 하 고 해당 상태를 업데이트 요청 수입니다."
  remarks: "인식기에서 생성 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>이벤트는 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>속성은 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>은 `null`.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>       사용자 토큰을 제공 하기 위해 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>또는 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 오디오 위치 오프셋을 지정 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>"
  syntax:
    content: public void RequestRecognizerUpdate ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  id: RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "요청은 공유 인식기에서 일시 중지 및 해당 상태를 업데이트 하 고 연결된 된 이벤트에 대 한 사용자 토큰을 제공 합니다."
  remarks: "인식기에서 생성 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>이벤트에는 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>의 속성은 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>의 값을 포함는 `userToken` 매개 변수.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>       오디오 위치 오프셋을 지정 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken);
    parameters:
    - id: userToken
      type: System.Object
      description: "작업에 대 한 정보를 포함 하는 사용자 정의 정보입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  id: RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "요청은 공유 인식기에서 일시 중지 및 해당 상태를 업데이트 하 고 연결된 된 이벤트에 대 한 오프셋 및 사용자 토큰을 제공 합니다."
  remarks: "인식기에서 인식기 될 때까지 인식기 업데이트 요청을 시작 하지 않고 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>현재 equals <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>값을 더한 값의 `audioPositionAheadToRaiseUpdate` 매개 변수.</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>       인식기에서 생성 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>이벤트에는 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>의 속성은 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>의 값을 포함는 `userToken` 매개 변수.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);
    parameters:
    - id: userToken
      type: System.Object
      description: "작업에 대 한 정보를 포함 하는 사용자 정의 정보입니다."
    - id: audioPositionAheadToRaiseUpdate
      type: System.TimeSpan
      description: "현재에서 오프셋 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition*>요청 지연.</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition*>"
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  id: SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechDetected
  nameWithType: SpeechRecognizer.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "인식기에서 음성으로 식별할 수 있는 입력을 감지할 때 발생 합니다."
  remarks: "공유 인식기에서 입력에 대 한 응답에서이 이벤트를 발생 시킬 수 있습니다. <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A>속성은 연결 된 <xref:System.Speech.Recognition.SpeechDetectedEventArgs>개체는 인식기에서 음성을 검색할 입력 스트림의 위치를 나타냅니다.</xref:System.Speech.Recognition.SpeechDetectedEventArgs> </xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> 자세한 내용은 참조는 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>및 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>속성 및 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>및 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>       SpeechDetected 이벤트에 대 한 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example is part of a console application for choosing origin and destination cities for a flight. The application recognizes phrases such as \"I want to fly from Miami to Chicago.\"  The example uses the SpeechDetected event to report the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> each time speech is detected.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        Choices cities = new Choices(new string[] {   \n          \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I would like to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Create a Grammar object and load it to the recognizer.  \n        Grammar g = new Grammar(gb);  \n        g.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(g);  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechDetected +=   \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech detected at AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs> SpeechDetected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  id: SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechHypothesized
  nameWithType: SpeechRecognizer.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "단어 또는 그러한 단어를 문법에 여러 전체 구의 구성 요소 수 있는 인식기에서 인식 하는 경우 발생 합니다."
  remarks: "공유 인식기에서 입력이 모호한 경우이 이벤트를 발생 시킬 수 있습니다. 지 원하는 인식의 음성 인식 문법에 대 한 예를 들어 &quot;새 게임을 하십시오&quot; 또는 &quot;새 게임&quot; &quot;새 게임을 하십시오&quot; 한 명확한 입력 하 고 &quot;새 게임&quot;은 모호한 입력 합니다.       SpeechHypothesized 이벤트에 대 한 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\". The example uses the SpeechHypothesized event to display incomplete phrase fragments in the console as they are recognized.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display the list of\");  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\");  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\");  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechHypothesized +=   \n          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech hypothesized: \" + e.Result.Text);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs> SpeechHypothesized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  id: SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognizer.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "인식기에서 음성 인식 문법이 로드와 일치 하지 않는 입력을 받으면 발생 합니다."
  remarks: "경우에 입력와 일치 하지 않으므로 충분 한 신뢰 된 로드 된 음성 인식 문법의 공유 인식기에서이 이벤트가 발생 합니다. <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>의 속성은 <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>거부 된 포함 <xref:System.Speech.Recognition.RecognitionResult>개체입니다.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>       관리 하는 공유 인식기에서에 대 한 신뢰도 임계값 <xref:System.Speech.Recognition.SpeechRecognizer>, 사용자 프로필에 연결 된 및 Windows 레지스트리에 저장 합니다.</xref:System.Speech.Recognition.SpeechRecognizer> 응용 프로그램에 공유 인식기에서의 속성에 대 한 레지스트리 변경 내용을 작성 해야 합니다.       SpeechRecognitionRejected 이벤트에 대 한 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the SpeechRecognitionRejected event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient confidence to produce a successful recognition.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechRecognitionRejected +=   \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech input was rejected.\");  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> SpeechRecognitionRejected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  id: SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognized
  nameWithType: SpeechRecognizer.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "인식기에서 음성 인식 문법의 중 하 나와 일치 하는 입력을 받으면 발생 합니다."
  remarks: "인식기 발생은 `SpeechRecognized` 입력 로드 하 고 사용할 음성 인식 문법 중 하 나와 일치 하는 충분 한 신뢰를 결정 하는 경우에 이벤트입니다. <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>의 속성은 <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>허용 포함 <xref:System.Speech.Recognition.RecognitionResult>개체입니다.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>       관리 하는 공유 인식기에서에 대 한 신뢰도 임계값 <xref:System.Speech.Recognition.SpeechRecognizer>, 사용자 프로필에 연결 된 및 Windows 레지스트리에 저장 합니다.</xref:System.Speech.Recognition.SpeechRecognizer> 응용 프로그램에 공유 인식기에서의 속성에 대 한 레지스트리 변경 내용을 작성 해야 합니다.       인식기 문법, 일치 하는 입력을 받을 때의 <xref:System.Speech.Recognition.Grammar>개체가 발생 시킬 수는 <xref:System.Speech.Recognition.Grammar.SpeechRecognized>이벤트.</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar> <xref:System.Speech.Recognition.Grammar>개체의 <xref:System.Speech.Recognition.Grammar.SpeechRecognized>음성 인식기 SpeechRecognized 이벤트 보다 먼저 발생 합니다.</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar>       SpeechRecognized 이벤트에 대 한 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates speech input to the shared recognizer, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.  \n  \n Spoken input such as \"I want to fly from Chicago to Miami\" will trigger a SpeechRecognized event. Speaking the phrase \"Fly me from Houston to Chicago \" will not trigger a SpeechRecognized event.  \n  \n The example uses a handler for the SpeechRecognized event to display successfully recognized phrases and the semantics they contain in the console.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create SemanticResultValue objects that contain cities and airport codes.  \n        SemanticResultValue chicago = new SemanticResultValue(\"Chicago\", \"ORD\");  \n        SemanticResultValue boston = new SemanticResultValue(\"Boston\", \"BOS\");  \n        SemanticResultValue miami = new SemanticResultValue(\"Miami\", \"MIA\");  \n        SemanticResultValue dallas = new SemanticResultValue(\"Dallas\", \"DFW\");  \n  \n        // Create a Choices object and add the SemanticResultValue objects, using  \n        // implicit conversion from SemanticResultValue to GrammarBuilder  \n        Choices cities = new Choices();  \n        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  \n  \n        // Build the phrase and add SemanticResultKeys.  \n        GrammarBuilder chooseCities = new GrammarBuilder();  \n        chooseCities.Append(\"I want to fly from\");  \n        chooseCities.Append(new SemanticResultKey(\"origin\", cities));  \n        chooseCities.Append(\"to\");  \n        chooseCities.Append(new SemanticResultKey(\"destination\", cities));  \n  \n        // Build a Grammar object from the GrammarBuilder.  \n        Grammar bookFlight = new Grammar(chooseCities);  \n        bookFlight.Name = \"Book Flight\";  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(bookFlight);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized:  \" + e.Result.Text);  \n      Console.WriteLine();  \n      Console.WriteLine(\"Semantic results:\");  \n      Console.WriteLine(\"  The flight origin is \" + e.Result.Semantics[\"origin\"].Value);  \n      Console.WriteLine(\"  The flight destination is \" + e.Result.Semantics[\"destination\"].Value);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs> SpeechRecognized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.State
  id: State
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: State
  nameWithType: SpeechRecognizer.State
  fullName: System.Speech.Recognition.SpeechRecognizer.State
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "상태를 가져옵니다는 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> 개체입니다."
  remarks: "이 읽기 전용 속성에 Windows 공유 인식기 인지 여부를 나타냅니다.는 `Stopped` 또는 `Listening` 상태입니다. 자세한 내용은 참조는 <xref:System.Speech.Recognition.RecognizerState>열거형.</xref:System.Speech.Recognition.RecognizerState>"
  syntax:
    content: public System.Speech.Recognition.RecognizerState State { get; }
    return:
      type: System.Speech.Recognition.RecognizerState
      description: "상태는 <xref uid=&quot;langword_csharp_SpeechRecognizer&quot; name=&quot;SpeechRecognizer&quot; href=&quot;&quot;> </xref> 개체입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.State*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.StateChanged
  id: StateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: StateChanged
  nameWithType: SpeechRecognizer.StateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.StateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Windows 바탕 화면 음성 기술 인식 엔진의 실행 상태가 변경 될 때 발생 합니다."
  remarks: "공유 인식기에서 음성 인식 Windows의 상태를 변경한 경우이 이벤트를 발생 시킵니다.는 <xref:System.Speech.Recognition.RecognizerState>또는 <xref:System.Speech.Recognition.RecognizerState>상태.</xref:System.Speech.Recognition.RecognizerState> </xref:System.Speech.Recognition.RecognizerState>       이벤트의 시간에 공유 인식기에서의 상태를 가져오려면 <xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> <xref:System.Speech.Recognition.StateChangedEventArgs>.</xref:System.Speech.Recognition.StateChangedEventArgs> 연결된의 속성</xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> 을 사용 하 여 공유 인식기에서의 현재 상태를 가져오려면 인식기에서 사용 하 여 <xref:System.Speech.Recognition.SpeechRecognizer.State%2A>속성.</xref:System.Speech.Recognition.SpeechRecognizer.State%2A>       StateChanged 이벤트에 대 한 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다. 대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 [이벤트 및 대리자](http://go.microsoft.com/fwlink/?LinkId=162418)합니다."
  example:
  - "The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example asynchronously loads all the created grammars to the recognizer.  A handler for the StateChanged event uses the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> method to put Windows Recognition in \"listening\" mode.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Add a handler for the LoadGrammarCompleted event.  \n      recognizer.LoadGrammarCompleted += new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n      // Add a handler for the SpeechRecognized event.  \n      recognizer.SpeechRecognized += new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n      // Add a handler for the StateChanged event.  \n      recognizer.StateChanged += new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n      // Create \"yesno\" grammar.  \n      Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yah}\" });  \n      SemanticResultValue yesValue =  \n          new SemanticResultValue(yesChoices, (bool)true);  \n      Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"nah\" });  \n      SemanticResultValue noValue = new SemanticResultValue(noChoices, (bool)false);  \n      SemanticResultKey yesNoKey =  \n          new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n      Grammar yesnoGrammar = new Grammar(yesNoKey);  \n      yesnoGrammar.Name = \"yesNo\";  \n  \n      // Create \"done\" grammar.  \n      Grammar doneGrammar =  \n        new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n      doneGrammar.Name = \"Done\";  \n  \n      // Create dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load grammars to the recognizer.  \n      recognizer.LoadGrammarAsync(yesnoGrammar);  \n      recognizer.LoadGrammarAsync(doneGrammar);  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void  recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n     if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void  recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n     Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void  recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n     string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n      }  \n  \n      // Add exception handling code here.  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.StateChangedEventArgs> StateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.StateChangedEventArgs}
      description: "추가할 수 있습니다."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  id: UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognizer.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "공유 인식기에서 모든 음성 인식 문법 언로드합니다."
  remarks: "인식기가 현재 문법 비동기적으로 로드 하는 경우이 메서드는 문법을 인식기 문법의 모든 언로드합니다 전에 로드 될 때까지 대기 합니다.       사용 하 여 특정 문법을 언로드하려면는 <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>"
  syntax:
    content: public void UnloadAllGrammars ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  id: UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognizer.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "공유 인식기에서 지정 된 음성 인식 문법을 언로드합니다."
  remarks: "응용 프로그램을 사용 해야 인식기에서 실행 중인 경우 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>를 로드, 언로드, 또는 사용 안 함 문법 하기 전에 음성 인식 엔진을 일시 중지 합니다.</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 모든 문법을 언로드하려면 사용은 <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>메서드.</xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>"
  syntax:
    content: public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "언로드할 문법입니다."
  overload: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar*
  exceptions: []
  platform:
  - net462
references:
- uid: System.Object
  isExternal: false
  name: System.Object
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognizer()
  nameWithType: SpeechRecognizer.SpeechRecognizer()
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognizer()
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioFormat
- uid: System.Speech.AudioFormat.SpeechAudioFormatInfo
  parent: System.Speech.AudioFormat
  isExternal: false
  name: SpeechAudioFormatInfo
  nameWithType: SpeechAudioFormatInfo
  fullName: System.Speech.AudioFormat.SpeechAudioFormatInfo
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevel
- uid: System.Int32
  parent: System
  isExternal: true
  name: Int32
  nameWithType: Int32
  fullName: System.Int32
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevelUpdated
  nameWithType: SpeechRecognizer.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
- uid: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioLevelUpdatedEventArgs>
  nameWithType: EventHandler<AudioLevelUpdatedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioLevelUpdatedEventArgs
    name: AudioLevelUpdatedEventArgs
    nameWithType: AudioLevelUpdatedEventArgs
    fullName: AudioLevelUpdatedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioPosition
- uid: System.TimeSpan
  parent: System
  isExternal: true
  name: TimeSpan
  nameWithType: TimeSpan
  fullName: System.TimeSpan
- uid: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognizer.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
- uid: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioSignalProblemOccurredEventArgs>
  nameWithType: EventHandler<AudioSignalProblemOccurredEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioSignalProblemOccurredEventArgs
    name: AudioSignalProblemOccurredEventArgs
    nameWithType: AudioSignalProblemOccurredEventArgs
    fullName: AudioSignalProblemOccurredEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioState
- uid: System.Speech.Recognition.AudioState
  parent: System.Speech.Recognition
  isExternal: false
  name: AudioState
  nameWithType: AudioState
  fullName: System.Speech.Recognition.AudioState
- uid: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioStateChanged
  nameWithType: SpeechRecognizer.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
- uid: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioStateChangedEventArgs>
  nameWithType: EventHandler<AudioStateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioStateChangedEventArgs
    name: AudioStateChangedEventArgs
    nameWithType: AudioStateChangedEventArgs
    fullName: AudioStateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose()
  nameWithType: SpeechRecognizer.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose()
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose(Boolean)
  nameWithType: SpeechRecognizer.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose(Boolean)
- uid: System.Boolean
  parent: System
  isExternal: true
  name: Boolean
  nameWithType: Boolean
  fullName: System.Boolean
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognizer.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String)
- uid: System.Speech.Recognition.RecognitionResult
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
- uid: System.String
  parent: System
  isExternal: true
  name: String
  nameWithType: String
  fullName: System.String
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.RecognizedWordUnit[]
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit[]
  spec.csharp:
  - uid: System.Speech.Recognition.RecognizedWordUnit
    name: RecognizedWordUnit
    nameWithType: RecognizedWordUnit
    fullName: RecognizedWordUnit[]
  - name: '[]'
    nameWithType: '[]'
    fullName: '[]'
- uid: System.Globalization.CompareOptions
  parent: System.Globalization
  isExternal: true
  name: CompareOptions
  nameWithType: CompareOptions
  fullName: System.Globalization.CompareOptions
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognizer.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<EmulateRecognizeCompletedEventArgs>
  nameWithType: EventHandler<EmulateRecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.EmulateRecognizeCompletedEventArgs
    name: EmulateRecognizeCompletedEventArgs
    nameWithType: EmulateRecognizeCompletedEventArgs
    fullName: EmulateRecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
  fullName: System.Speech.Recognition.SpeechRecognizer.Enabled
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
  fullName: System.Speech.Recognition.SpeechRecognizer.Grammars
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<Grammar>
  nameWithType: ReadOnlyCollection<Grammar>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.Grammar>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.Grammar
    name: Grammar
    nameWithType: Grammar
    fullName: Grammar
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(Grammar)
- uid: System.Speech.Recognition.Grammar
  parent: System.Speech.Recognition
  isExternal: false
  name: Grammar
  nameWithType: Grammar
  fullName: System.Speech.Recognition.Grammar
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(Grammar)
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognizer.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
- uid: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<LoadGrammarCompletedEventArgs>
  nameWithType: EventHandler<LoadGrammarCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.LoadGrammarCompletedEventArgs
    name: LoadGrammarCompletedEventArgs
    nameWithType: LoadGrammarCompletedEventArgs
    fullName: LoadGrammarCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
  fullName: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
- uid: System.Speech.Recognition.RecognizerInfo
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerInfo
  nameWithType: RecognizerInfo
  fullName: System.Speech.Recognition.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognizer.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
- uid: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizerUpdateReachedEventArgs>
  nameWithType: EventHandler<RecognizerUpdateReachedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerUpdateReachedEventArgs
    name: RecognizerUpdateReachedEventArgs
    nameWithType: RecognizerUpdateReachedEventArgs
    fullName: RecognizerUpdateReachedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate()
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object)
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechDetected
  nameWithType: SpeechRecognizer.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
- uid: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechDetectedEventArgs>
  nameWithType: EventHandler<SpeechDetectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechDetectedEventArgs
    name: SpeechDetectedEventArgs
    nameWithType: SpeechDetectedEventArgs
    fullName: SpeechDetectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechHypothesized
  nameWithType: SpeechRecognizer.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
- uid: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechHypothesizedEventArgs>
  nameWithType: EventHandler<SpeechHypothesizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechHypothesizedEventArgs
    name: SpeechHypothesizedEventArgs
    nameWithType: SpeechHypothesizedEventArgs
    fullName: SpeechHypothesizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognizer.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognitionRejectedEventArgs>
  nameWithType: EventHandler<SpeechRecognitionRejectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognitionRejectedEventArgs
    name: SpeechRecognitionRejectedEventArgs
    nameWithType: SpeechRecognitionRejectedEventArgs
    fullName: SpeechRecognitionRejectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognized
  nameWithType: SpeechRecognizer.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognizedEventArgs>
  nameWithType: EventHandler<SpeechRecognizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognizedEventArgs
    name: SpeechRecognizedEventArgs
    nameWithType: SpeechRecognizedEventArgs
    fullName: SpeechRecognizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.State
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: State
  nameWithType: SpeechRecognizer.State
  fullName: System.Speech.Recognition.SpeechRecognizer.State
- uid: System.Speech.Recognition.RecognizerState
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerState
  nameWithType: RecognizerState
  fullName: System.Speech.Recognition.RecognizerState
- uid: System.Speech.Recognition.SpeechRecognizer.StateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: StateChanged
  nameWithType: SpeechRecognizer.StateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.StateChanged
- uid: System.EventHandler{System.Speech.Recognition.StateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<StateChangedEventArgs>
  nameWithType: EventHandler<StateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.StateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.StateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.StateChangedEventArgs
    name: StateChangedEventArgs
    nameWithType: StateChangedEventArgs
    fullName: StateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognizer.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars()
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognizer.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(Grammar)
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognizer
  nameWithType: SpeechRecognizer.SpeechRecognizer
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose
  nameWithType: SpeechRecognizer.Dispose
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize
  nameWithType: SpeechRecognizer.EmulateRecognize
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammar
  nameWithType: SpeechRecognizer.LoadGrammar
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarAsync
  nameWithType: SpeechRecognizer.LoadGrammarAsync
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate
- uid: System.Speech.Recognition.SpeechRecognizer.State*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: State
  nameWithType: SpeechRecognizer.State
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadAllGrammars
  nameWithType: SpeechRecognizer.UnloadAllGrammars
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadGrammar
  nameWithType: SpeechRecognizer.UnloadGrammar
